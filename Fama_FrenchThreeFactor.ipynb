{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19ZXmI4B9Ow7ea_NiZBPF2Vp03A0-7Jky",
      "authorship_tag": "ABX9TyOQtW/+lDZlcGJ0Mja+scal",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahVSargent/stock_signals_regressions/blob/main/Fama_FrenchThreeFactor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intro"
      ],
      "metadata": {
        "id": "FSaHyqpeHKHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#coonnect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-xFs-Y5G3DG",
        "outputId": "1bfdcf08-b07d-4a87-c3cc-1df894be9d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tools\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "!pip install pandasql\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from scipy.stats.mstats import winsorize\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import pandasql as ps"
      ],
      "metadata": {
        "id": "PRPKsQPkHGuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Fama-french 5 factor/CRSPMonthly1990Through2022.csv\"\n",
        "CRSPMonthly1990Through2022 = pd.read_csv(file)\n",
        "print(CRSPMonthly1990Through2022.columns)\n",
        "\n",
        "file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Fama-french 5 factor/FamaFrenchFiveFactorsMonthly.csv\"\n",
        "FamaFrenchFiveFactorsMonthly = pd.read_csv(file)\n",
        "print(FamaFrenchFiveFactorsMonthly.columns)\n",
        "\n",
        "file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Fama-french 5 factor/ccmfund1990to2022.csv\"\n",
        "ccmfund1990to2022 = pd.read_csv(file)\n",
        "print(ccmfund1990to2022.columns)\n",
        "\n",
        "print(\"imported\")"
      ],
      "metadata": {
        "id": "zzcGFflTHi6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "clean just CRSP"
      ],
      "metadata": {
        "id": "sg3y4U-ROitM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4:53\n",
        "\n",
        "#only keeping these relevant variables\n",
        "CRSPMonthly1990Through2022= CRSPMonthly1990Through2022[[\"PERMO\", \"date\", \"RET\", \"SHROUT\", \"ALTPRC\", \"EXCHCD\", \"SHRCD\", \"SICCD\", \"DLRET\", \"DLSTCD\"]]\n",
        "#drop duplicates (instead of slect distinct)\n",
        "CRSPMonthly1990Through2022.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "-8CiPKtMI2RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5:10\n",
        "\n",
        "#convert variables to numeric- nessesary? Yes, good practice\n",
        "CRSPMonthly1990Through2022['PERMO']= pd.to_numeric(CRSPMonthly1990Through2022['PERMO'], errors= 'coerce')\n",
        "CRSPMonthly1990Through2022['date']= pd.to_numeric(CRSPMonthly1990Through2022['date'], format= '%Y%m%d')\n",
        "CRSPMonthly1990Through2022['RET']= pd.to_numeric(CRSPMonthly1990Through2022['RET'], errors= 'coerce')\n",
        "CRSPMonthly1990Through2022['SHROUT']= pd.to_numeric(CRSPMonthly1990Through2022['SHROUT'], errors= 'coerce')\n",
        "CRSPMonthly1990Through2022['ALTPRC']= pd.to_numeric(CRSPMonthly1990Through2022['ALTPRC'], errors= 'coerce')\n",
        "CRSPMonthly1990Through2022['EXCHCD']= pd.to_numeric(CRSPMonthly1990Through2022['EXCHCD'], errors= 'coerce')\n",
        "CRSPMonthly1990Through2022['SHRCD']= pd.to_numeric(CRSPMonthly1990Through2022['SHRCD'], errors= 'coerce')\n",
        "CRSPMonthly1990Through2022['SICCD']= pd.to_numeric(CRSPMonthly1990Through2022['SICCD'], errors= 'coerce')\n",
        "CRSPMonthly1990Through2022['DLRET']= pd.to_numeric(CRSPMonthly1990Through2022['DLRET'], errors= 'coerce')\n",
        "CRSPMonthly1990Through2022['DLSTCD']= pd.to_numeric(CRSPMonthly1990Through2022['DLSTCD'], errors= 'coerce')\n",
        "\n",
        "#convert returns to percent\n",
        "CRSPMonthly1990Through2022['RET'] *=100\n",
        "CRSPMonthly1990Through2022['DLRET'] *=100\n"
      ],
      "metadata": {
        "id": "ACFVa6D2OpMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5:30\n",
        "\n",
        "#only data rows after 2018\n",
        "CRSP2018to2022= CRSPMonthly1990Through2022[CRSPMonthly1990Through2022['date']>= \"2018-01-01\"]\n",
        "\n",
        "#only data rows in US\n",
        "#what numbers mean?- only index\n",
        "CRSP2018to2022= CRSP2018to2022[(CRSP2018to2022['SHRCD']==10) | (CRSP2018to2022['SHRCD']==11)]"
      ],
      "metadata": {
        "id": "AqpHuhbKPRXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate market cap (millions) per row/ calculated column/ new column/ add column\n",
        "#market cap is total value, shrout is SHaRes OUTstanding, altprc\n",
        "CRSP2018to2022['market_cap']= abs(CRSP2018to2022['SHROUT']*CRSP2018to2022['ALTPRC'])/1000\n",
        "#explain this?, inplace not there before\n",
        "#replacing np.nan (null) rows with 0, will drop later on\n",
        "CRSP2018to2022['market_cap'].replace(0, np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "b385tr1cQzpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5:56\n",
        "#add exchange column\n",
        "#define exchange labels and keep only relevant labels\n",
        "\n",
        "#1 or 31, traded on NYSE, etc.\n",
        "CRSP2018to2022['exchange'] = \"\"\n",
        "for i in CRSP2018to2022.index:\n",
        "  if CRSP2018to2022['EXCHCD'][i] in [1, 31]:\n",
        "    CRSP2018to2022['exchange'][i] = \"NYSE\"\n",
        "  elif CRSP2018to2022['EXCHCD'][i] in [2, 32]:\n",
        "    CRSP2018to2022['exchange'][i] = \"AMEX\"\n",
        "  elif CRSP2018to2022['EXCHCD'][i] in [3, 33]:\n",
        "    CRSP2018to2022['exchange'][i] = \"NASDAQ\"\n",
        "  else:\n",
        "    CRSP2018to2022['exchange'][i] = \"Other\"\n",
        "#filter out exchanges of other type ?. ! means inequality. So, keep everything but other\n",
        "CRSP2018to2022= CRSP2018to2022[CRSP2018to2022['exchange'] != \"Other\"]\n"
      ],
      "metadata": {
        "id": "8Fnacck6V0tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6:30\n",
        "#add adjusted return column\n",
        "#creating new column, all values null\n",
        "#np.nan is for numbers, as opposed to blank\n",
        "CRSP2018to2022['ret_adj']= np.nan\n",
        "#i is variable\n",
        "for i in CRSP2018to2022.index:\n",
        "#[column][row],\n",
        "  if pd.isnull(CRSP2018to2022['DLSTCD'][i]):\n",
        "    CRSP2018to2022['ret_adj'][i] = CRSP2018to2022['ret'][i]\n",
        "  elif(pd.notnull(CRSP2018to2022['DLSTCD'][i])) and (pd.notnull(CRSP2018to2022['DLRET'][i])):\n",
        "    CRSP2018to2022['ret_adj'][i] = CRSP2018to2022['DLSTCD'][i]\n",
        "#what numbers range mean- index, defined in codebook\n",
        "  elif(551<=CRSP2018to2022['DLSTCD'][i]<=574) or (CRSP2018to2022['DLSTCD'][i] in [500,520,580,584]):\n",
        "    CRSP2018to2022['ret_adj'][i] = -30\n",
        "  else:\n",
        "    CRSP2018to2022['ret_adj'][i] = -100\n",
        "\n"
      ],
      "metadata": {
        "id": "IqqLlR9EZclP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6:40\n",
        "#drop unneeded collumns, neater dataframe\n",
        "\n",
        "#no need for pandas, only sequel\n",
        "#CRSP2018to2022= CRSP2018to2022.reset_index()\n",
        "\n",
        "#axis 0 is certain row (implicit), axis 1 is certain columns (have to make explicit)\n",
        "CRSP2018to2022.drop(['SHRCD', 'DLRET', 'DLSTCD'], inplace=True, axis=1)\n",
        "\n",
        "print(CRSP2018to2022)\n",
        "print(CRSP2018to2022.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "JCwAJ2b4c0tC",
        "outputId": "3fd2ccdc-27ed-444a-9caa-c975afebf1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-64828a11a4b4>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#axis 0 is certain row (implicit), axis 1 is certain columns (have to make explicit)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mCRSP2018to2022\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shrcd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dlret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dlstcd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCRSP2018to2022\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CRSP2018to2022' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clean CCM data"
      ],
      "metadata": {
        "id": "3EIxE68CIy7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#only keeping these relevant variables\n",
        "ccmfund1990to2022= ccmfund1990to2022[[\"GVKEY\", \"LPERMINO\", \"datadate\", \"LINKTYPE\", \"LINKENDDT\", \"seq\", \"ceq\", \"at\", \"lt\", \"txditc\",\"txdb\", \"itcb\", \"pstkrv\", \"pstkl\", \"pstk\", \"indfmt\", \"datafmt\"]]\n",
        "#drop duplicates (instead of slect distinct)\n",
        "ccmfund1990to2022.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "I7HUvxTjITvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7:57\n",
        "\n",
        "ccmfund1990to2022['GVKEY']= pd.to_numeric(ccmfund1990to2022['GVKEY'], errors= 'coerce')\n",
        "ccmfund1990to2022['LPERMINO']= pd.to_numeric(ccmfund1990to2022['LPERMINO'], errors= 'coerce')\n",
        "ccmfund1990to2022['datadate']= pd.to_numeric(ccmfund1990to2022['datadate'], format= '%Y%m%d')\n",
        "ccmfund1990to2022['LINKTYPE']= ccmfund1990to2022['LINKTYPE'].apply(str)\n",
        "ccmfund1990to2022['LINKENDDT']= pd.to_numeric(ccmfund1990to2022['LINKENDDT'], format= '%Y%m%d')\n",
        "ccmfund1990to2022['seq']= pd.to_numeric(ccmfund1990to2022['seq'], errors= 'coerce')\n",
        "ccmfund1990to2022['ceq']= pd.to_numeric(ccmfund1990to2022['ceq'], errors= 'coerce')\n",
        "ccmfund1990to2022['at']= pd.to_numeric(ccmfund1990to2022['at'], errors= 'coerce')\n",
        "ccmfund1990to2022['lt']= pd.to_numeric(ccmfund1990to2022['lt'], errors= 'coerce')\n",
        "ccmfund1990to2022['txditc']= pd.to_numeric(ccmfund1990to2022['txditc'], errors= 'coerce')\n",
        "ccmfund1990to2022['txdb']= pd.to_numeric(ccmfund1990to2022['txdb'], errors= 'coerce')\n",
        "ccmfund1990to2022['itcb']= pd.to_numeric(ccmfund1990to2022['itcb'], errors= 'coerce')\n",
        "ccmfund1990to2022['pstkrv']= pd.to_numeric(ccmfund1990to2022['pstkrv'], errors= 'coerce')\n",
        "ccmfund1990to2022['pstkl']= pd.to_numeric(ccmfund1990to2022['pstkl'], errors= 'coerce')\n",
        "ccmfund1990to2022['pstk']= pd.to_numeric(ccmfund1990to2022['pstk'], errors= 'coerce')\n",
        "\n",
        "ccmfund1990to2022['indfmt']= ccmfund1990to2022['indfmt'].apply(str)\n",
        "ccmfund1990to2022['datafmt']= ccmfund1990to2022['datafmt'].apply(str)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "UiPz450tLBcK",
        "outputId": "670a7b9e-b765-4075-f265-9fd83671157f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6305894d9cfa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GVKEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GVKEY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LPERMINO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LPERMINO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datadate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datadate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'%Y%m%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LINKTYPE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LINKTYPE'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LINKENDDT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mccmfund1990to2022\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LINKENDDT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8:04\n",
        "\n",
        "#only data rows after 2018\n",
        "ccmfund2018to2022= ccmfund1990to2022[ccmfund1990to2022['date']>= \"2018-01-01 00:00:00\"]\n",
        "\n",
        "#only keep data in correct format\n",
        "ccmfund1990to2022= ccmfund1990to2022[ccmfund1990to2022['indmt']==\"INTL\"]\n",
        "ccmfund1990to2022= ccmfund1990to2022[ccmfund1990to2022['datafmt']==\"STD\"]\n",
        "\n",
        "#only keep valid links\n",
        "ccmfund1990to2022= ccmfund1990to2022[(ccmfund1990to2022['LINKTYPE']==\"LU\")| (ccmfund1990to2022['LINKTYPE']== \"LC\")]\n",
        "\n",
        "#only keep links active at datadate\n",
        "ccmfund1990to2022= ccmfund1990to2022[(ccmfund1990to2022['datadate']<= ccmfund1990to2022['LINKENDDT'])| pd.isnull(ccmfund1990to2022['LINKENDDT'])]\n"
      ],
      "metadata": {
        "id": "oaTeGlxzVhep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8:42\n",
        "\n",
        "#book value calculated column\n",
        "\n",
        "#?replace or vs coalesce\n",
        "#ccmfund1990to2022['book_value']= abs(ccmfund1990to2022['seq']*CRSP2018to2022['ALTPRC'])\n",
        "#df['A'].combine_first(df['B'])\n",
        "#df['c'] = np.where(df[\"a\"].isnull(), df[\"b\"], df[\"a\"] )\n",
        "\n",
        "\n",
        "\n",
        "#variable a\n",
        "#variable b\n",
        "#variable c\n",
        "\n",
        "ccmfund1990to2022['book_value']= ccmfund1990to2022.ccmfund1990to2022['seq'].combine_first(ccmfund1990to2022.b)\n",
        "\n",
        "\n",
        "#explain this?, inplace not there before\n",
        "#replacing np.nan (null) rows with 0, will drop later on\n",
        "ccmfund1990to2022['book_value'].replace(0, np.nan, inplace=True)\n"
      ],
      "metadata": {
        "id": "WHXBlBC8ZGSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculated column for operating profitability op\n",
        "\n",
        "#variable a\n",
        "#variable b\n",
        "#variable c\n"
      ],
      "metadata": {
        "id": "uK2Cx59-6OOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8:57\n",
        "\n",
        "#keep only the last observation of each year\n",
        "ccmfund1990to2022['datadate']= pd.to_datetime(ccmfund1990to2022['datadate'])\n",
        "ccmfund1990to2022['year']= ccmfund1990to2022['datadate'].dt.year\n",
        "ccmfund1990to2022= ccmfund1990to2022.sort_values(by= ['PERMO', \"datadate\"], ascending= True)\n",
        "\n",
        "###????\n",
        "ccmfund1990to2022.drop(['SHRCD', 'DLRET', 'DLSTCD'], inplace=True, axis=1)\n",
        "\n",
        "print(CRSP2018to2022)\n",
        "print(CRSP2018to2022.columns)\n"
      ],
      "metadata": {
        "id": "WxLdShPQc7_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9:15\n",
        "#drop missing/infinite values\n",
        "\n",
        "ccmfund1990to2022.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "ccmfund1990to2022= ccmfund1990to2022.dropna()\n",
        "\n"
      ],
      "metadata": {
        "id": "dGgkiEN2hxC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9:21\n",
        "#add reference date column (for matching; june 1 6/1 of next calander year)\n",
        "ccmfund1990to2022['year']= pd.to_numeric(ccmfund1990to2022['year'], errors= 'coerce')\n",
        "ccmfund1990to2022['reference_date']= ccmfund1990to2022['year'] +1\n",
        "ccmfund1990to2022['reference_date']= ccmfund1990to2022['reference_date'].apply(str)\n",
        "#add year to string\n",
        "ccmfund1990to2022['reference_date']+= \"-06-01\"\n",
        "ccmfund1990to2022['reference_date']= pd.to_datetime(ccmfund1990to2022['reference_date'])\n",
        "ccmfund1990to2022.drop('year', inplace= True, axis=1 )\n",
        "\n",
        "print(ccmfund1990to2022)\n",
        "print(ccmfund1990to2022.columns)"
      ],
      "metadata": {
        "id": "gHrfXTN-HHM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CRSP #CRSP2018to2022 AND COMPUSTAT #ccmfund1990to2022"
      ],
      "metadata": {
        "id": "j5l_qTVWVn-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#9:44\n",
        "#parse relevant CRSP variables and store as stocks dataframe\n",
        "\n",
        "#only keeping these relevant variables\n",
        "#substitute for select distinct\n",
        "stonks2018To2022= CRSPMonthly1990Through2022[[\"PERMO\", \"date\", \"ret_adj\",\"market_cap\"]]\n",
        "#drop duplicates (instead of select distinct)\n",
        "stonks2018To2022.drop_duplicates(inplace=True)\n",
        "\n",
        "#drop infinite/missing values\n",
        "stonks2018To2022.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "stonks2018To2022= stonks2018To2022.dropna()\n"
      ],
      "metadata": {
        "id": "gavL-PmOJxPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9:55\n",
        "#add reference date to merdge stonks and cmmfund\n",
        "\n",
        "stonks2018To2022['date']= pd.to_datetime(stonks2018To2022['date'])\n",
        "stonks2018To2022['reference_date']= \"\"\n",
        "for i in stonks2018To2022.index:\n",
        "  if stonks2018To2022['date'][i].month<6:\n",
        "    stonks2018To2022['reference_date'][i]= str(stonks2018To2022['date['][i].year-1)+\"-06-01\"\n",
        "  else:\n",
        "    stonks2018To2022['reference_date'][i]= str(stonks2018To2022['date['][i].year)+\"-06-01\"\n",
        "stonks2018To2022['reference_date']= pd.to_datetime(stonks2018To2022['reference_date'])\n"
      ],
      "metadata": {
        "id": "xyyenmQ3NOmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10:16\n",
        "\n",
        "#merdge ccm dataframe into stoncks dataframe\n",
        "#left join\n",
        "ccmfund1990to2022.join(stonks2018To2022, on= 'permo' and 'reference_date', how='left')\n",
        "#left_df.merge(right_df.rename({'user_id': 'user_id_r'}, axis=1),left_on='user_id', right_on='user_id_r', how='left')\n",
        "#what's the name of df now?\n",
        "\n",
        "df.drop('index', inplace= True, axis=1)"
      ],
      "metadata": {
        "id": "6wweXCpTO0ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10:31\n",
        "\n",
        "#add market equity (for small vs big)\n",
        "\n",
        "stonks2018To2022['date']= pd.to_datetime(stonks2018To2022['date'])\n",
        "#only taking dates in the month of december?\n",
        "stocksMarketEquity= stonks2018To2022[stonks2018To2022['date'].dt.month ==12]\n",
        "stocksMarketEquity['reference_date']= stonks2018To2022['date'].dt.year +1\n",
        "stocksMarketEquity['reference_date']= stonks2018To2022['reference_date'].apply(str)\n",
        "#add year to string\n",
        "stocksMarketEquity['reference_date']+= \"-06-01\"\n",
        "stocksMarketEquity['reference_date']= pd.to_datetime(stocksMarketEquity['reference_date'])\n",
        "\n",
        "#parse/ only selecting relevant variables\n",
        "stocksMarketEquity= stocksMarketEquity[[\"PERMO\", \"reference_date\", \"market_cap\"]]\n",
        "#rename column market cap to market equity\n",
        "stocksMarketEquity.rename(columns={'market_cap': 'market_equity'}, inplace=True)\n",
        "#drop duplicates (instead of select distinct)\n",
        "stocksMarketEquity.drop_duplicates(inplace=True)\n",
        "\n",
        "\n",
        "#left join marketequity to stonks\n",
        "stonks2018To2022.merge(stocksMarketEquity.rename({'PERMO': 'PERMO'}, axis=1),left_on='PERMO', right_on='PERMO', how='left')\n",
        "\n",
        "#clean stonks\n",
        "stonks2018To2022.drop('index', inplace= True, axis= 1)\n",
        "stonks2018To2022= stonks2018To2022.dropna()"
      ],
      "metadata": {
        "id": "s2gEFFpRSYPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11:03\n",
        "#add book to market and market cap columns (for growth neutral value)\n",
        "\n",
        "\n",
        "stonks2018To2022['bm_ratio']= stonks2018To2022['book_value']/ stonks2018To2022['market_equity']\n",
        "\n",
        "#add market cap of june of year y of reference data\n",
        "stonks2018To2022['date']= pd.to_datetime(stonks2018To2022['date'])\n",
        "#only taking dates in the month of december?\n",
        "stocksWeight= stonks2018To2022[stonks2018To2022['date'].dt.month ==6]\n",
        "\n",
        "##parse/ only selecting relevant variables\n",
        "#stocksMarketEquity= stocksMarketEquity[[\"PERMO\", \"reference_date\", \"market_cap\"]]\n",
        "##rename column market cap to market equity\n",
        "#stocksMarketEquity.rename(columns={'market_cap': 'market_equity'}, inplace=True)\n",
        "#drop duplicates (instead of select distinct)\n",
        "stocksWeight.drop_duplicates(inplace=True)\n",
        "\n",
        "\n",
        "#left join marketequity to stonks?\n",
        "stonks2018To2022.merge(stocksWeight.rename({'PERMO': 'PERMO'}, axis=1),left_on='PERMO', right_on='PERMO', how='left')\n",
        "\n",
        "#rename column\n",
        "stonks2018To2022.rename(columns={'market_cap': 'market_cap_equity'}, inplace=True)\n",
        "\n",
        "#clean stonks\n",
        "stonks2018To2022.drop('index', inplace= True, axis= 1)\n"
      ],
      "metadata": {
        "id": "egopkUzeSxQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11:11\n",
        "\n",
        "#quick filter of null and infiite, only keep dates after 2020 (OR 2018???)\n",
        "\n",
        "stonks2018To2022.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "stonks2018To2022= stonks2018To2022.dropna()\n",
        "\n",
        "stonks2018To2022['date']= pd.to_datetime(stonks2018To2022['date'])\n",
        "stonks2018To2022= stonks2018To2022[stonks2018To2022['date'] >= '2020-01-01 00:00:00']\n"
      ],
      "metadata": {
        "id": "U_GVolLQTMDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Factor: smb sorting"
      ],
      "metadata": {
        "id": "I14MFrDbTi8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#11:29\n",
        "#only data in june\n",
        "\n",
        "stonks2018To2022['date']= pd.to_datetime(stonks2018To2022['date'])\n",
        "sizeBreakpoints= stonks2018To2022[(stonks2018To2022['date'].dt.month== 6) & (stonks2018To2022['exchange']== \"NYSE\")]\n",
        "sizeBreakpoints= sizeBreakpoints['PERMO','reference_date','market_cap']\n",
        "sizeBreakpoints['reference_date']= pd.to_datetime(sizeBreakpoints['reference_date'])\n",
        "g= sizeBreakpoints.groupby(['reference_date'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uwGw9nkrTocV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11:51\n",
        "#create size sorts and add median size column\n",
        "\n",
        "\n",
        "#should i be using sizebreakpoints?\n",
        "sizesorts= stonks2018To2022[(stonks2018To2022['date'].dt.month== 6)]\n",
        "\n",
        "sizesorts['size_median']=\"\"\n",
        "#median or .quantile(0.5)\n",
        "for i in sizesorts.index:\n",
        "    sizesorts['size_median'][i]= g.get_group(sizesorts['reference_date'][i]).reset_index()['market_cap'].median()\n",
        "\n"
      ],
      "metadata": {
        "id": "uhcz1TVEoClQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12:15\n",
        "#sort firms based on size\n",
        "\n",
        "sizesorts[\"size_portfolio\"]= \"\"\n",
        "for i in sizesorts.index:\n",
        "  if sizesorts[\"market_cap\"][i] > sizesorts['size_median'][i]:\n",
        "    sizesort[i][\"size_portfolio\"]= \"B\"\n",
        "  else:\n",
        "    sizesort[i][\"size_portfolio\"]= \"S\"\n"
      ],
      "metadata": {
        "id": "4dpDltKFMj2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#add size sorts data into stocks\n",
        "\n",
        "#drop duplicates (instead of select distinct)\n",
        "sizesort.drop_duplicates(inplace=True)\n",
        "\n",
        "#left join marketequity to stonks?\n",
        "stonks2018To2022.merge(sizesort.rename({'reference_date': 'reference_date', 'PERMO':'PERMO'} , axis=1),left_on='PERMO', right_on='PERMO', how='left')\n"
      ],
      "metadata": {
        "id": "QNjcPci7NlZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Value factor sort"
      ],
      "metadata": {
        "id": "AbewjWneOPq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#12:35\n",
        "#only data in june\n",
        "\n",
        "stonks2018To2022['date']= pd.to_datetime(stonks2018To2022['date'])\n",
        "valueBreakpoints= stonks2018To2022[(stonks2018To2022['date'].dt.month== 6) & (stonks2018To2022['exchange']== \"NYSE\")]\n",
        "valueBreakpoints= valueBreakpoints['PERMO','reference_date','market_cap']\n",
        "sizeBreakpoints['reference_date']= pd.to_datetime(sizeBreakpoints['reference_date'])\n",
        "g= sizeBreakpoints.groupby(['reference_date'])\n"
      ],
      "metadata": {
        "id": "sOuCLsQROOyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12:47\n",
        "#calculate 30th and 70th percentiles\n",
        "\n",
        "\n",
        "#should i be using sizebreakpoints?\n",
        "valuesorts= stonks2018To2022[(stonks2018To2022['date'].dt.month== 6)]\n",
        "\n",
        "#creation of variables?\n",
        "valuesorts['value_q30']=\"\"\n",
        "valuesorts['value_q70']=\"\"\n",
        "#explain this\n",
        "for i in sizesorts.index:\n",
        "    valuesorts['value_q30'][i]= g.get_group(g.get_group(valuesorts['reference_date'][i]).reset_index()['reference_date'][0])['bm_ratio'].quantile(0.3)\n",
        "    valuesorts['value_q70'][i]= g.get_group(g.get_group(valuesorts['reference_date'][i]).reset_index()['reference_date'][0])['bm_ratio'].quantile(0.7)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0CoZUO3dRGO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12:53\n",
        "#sort based on value, neatral, growth (H, M, L)\n",
        "\n",
        "valuesorts['value_portfolio']=\"\"\n",
        "for i in valuesorts.index:\n",
        "    if valuesorts['bm_ratio'][i]>= valuesorts['value_q70'][i]:\n",
        "       valuesorts['value_portfolio'][i]= \"H\"\n",
        "    elif valuesorts['bm_ratio'][i]> valuesorts['value_q30'][i]:\n",
        "       valuesorts[i][\"value_portfolio\"]= \"L\"\n",
        "    else:\n",
        "         valuesorts[i][\"value_portfolio\"]= \"M\""
      ],
      "metadata": {
        "id": "Znev7BLJSMzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13:01\n",
        "#add size sorts data into stocks\n",
        "\n",
        "#drop duplicates (instead of select distinct)\n",
        "valuesorts.drop_duplicates(inplace=True)\n",
        "\n",
        "#left join marketequity to stonks?\n",
        "stonks2018To2022.merge(valuesorts.rename({'reference_date': 'reference_date', 'PERMO':'PERMO'} , axis=1),left_on='PERMO', right_on='PERMO', how='left')\n"
      ],
      "metadata": {
        "id": "hC1gYkdPcqb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "merdging dataframes and factors"
      ],
      "metadata": {
        "id": "QNn9lo6ydM2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#13:25\n",
        "#new groupby variable for avg weighted returns\n",
        "stonks2018To2022['date']= pd.to_datetime(stonks2018To2022['date'])\n",
        "\n",
        "valweightedret= stonks2018To2022.groupby(['date', 'size_portfolio', 'value_portfolio']).apply(lambda x: np.average(pd.to_numeric(x['ret']), weights=pd.to_numeric(x['market_cap_weight'])))\n"
      ],
      "metadata": {
        "id": "2wgJVfqMdCVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14:01\n",
        "#create factors dataframe using only only\n",
        "\n",
        "factors=stonks2018To2022['date']\n",
        "factors.drop_duplicates(inplace=True)\n",
        "factors['date']= pd.to_datetime(factors['date'])\n"
      ],
      "metadata": {
        "id": "HaD_rL_-eixS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14:09\n",
        "#add in three factors smb, hml, mkt ret\n",
        "\n",
        "factors['smb']=\"\"\n",
        "#what is index?\n",
        "for i in factors.index:\n",
        "  dateofdata= factors['date'][i]\n",
        "  factors['smb'][i]= np.average(valweightedret[dateofdata][\"S\"])- np.average(valweightedret[dateofdata][\"B\"])\n",
        "#what does groupby do and what does line mean\n",
        "#does order matter?\n",
        "valweightedret= stonks2018To2022.groupby(['date', 'value_portfolio', 'size_portfolio']).apply(lambda x: np.average(pd.to_numeric(x['ret']), weights=pd.to_numeric(x['market_cap_weight'])))\n",
        "\n",
        "factors['hml']=\"\"\n",
        "for i in factors.index:\n",
        "  dateofdata= factors['date'][i]\n",
        "  factors['hml'][i]= np.average(valweightedret[dateofdata][\"H\"])- np.average(valweightedret[dateofdata][\"L\"])\n",
        "\n",
        "factors['mkt_ret']=\"\"\n",
        "weightedavgmonthlyret= stonks2018To2022.groupby(['date']).apply(lambda x: np.average(pd.to_numeric(x['ret']), weights=pd.to_numeric(x['market_cap_weight'])))\n",
        "for i in factors.index:\n",
        "  dateofdata= factors['date'][i]\n",
        "  factors['mkt_ret'][i]= weightedavgmonthlyret[dateofdata]\n",
        "\n"
      ],
      "metadata": {
        "id": "f51BGfcyfqpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#14:43\n",
        "#clean\n",
        "\n",
        "#Take out last month- ret= 100% due to missing dlret data??\n",
        "factors['date']= pd.to_datetime(factors[['date']])\n",
        "factors= factors[factors['date']< '2022-03-31']\n",
        "\n",
        "factors.drop_duplicates(inplace=True)\n",
        "\n",
        "#substitute for select distinct\n",
        "#why not including company name?\n",
        "factors= factors[[\"date\", \"mkt_ret\", \"smb\",\"hml\"]]\n"
      ],
      "metadata": {
        "id": "mvjUbt6UqiqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15:00\n",
        "#ensure factors sorted by date\n",
        "factors['date']= pd.to_datetime(factors[['date']])\n",
        "factors= factors.sort_values(by=['date'], ascending= True)\n"
      ],
      "metadata": {
        "id": "4OVTyshVrd58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean ff data"
      ],
      "metadata": {
        "id": "GddL76YrsJyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#15:12\n",
        "#import fama-french data\n",
        "\n",
        "print(FamaFrenchFiveFactorsMonthly)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "QtAHpEtbr0LR",
        "outputId": "a2499d5a-4d79-40ce-be05-ea76b3d738f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1539d3bd98e5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#import fama-french data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFamaFrenchFiveFactorsMonthly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'FamaFrenchFiveFactorsMonthly' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15:32\n",
        "\n",
        "#rename column Date to date, etc\n",
        "FFFFmonthly=FamaFrenchFiveFactorsMonthly\n",
        "\n",
        "FFFFmonthly.rename(columns={'Date': 'date', \"Mkt_RF - RF\": \"mkt_ff\", \"SMB\": \"smb_ff\", \"HML\": \"hml_ff\"}, inplace=True)\n"
      ],
      "metadata": {
        "id": "oKu1rtbPsO0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15:35\n",
        "#convert variables\n",
        "\n",
        "FFFFmonthly[mkt_ff]= pd.to_numeric(FFFFmonthly[mkt_ff] , errors='coerce')\n",
        "FFFFmonthly[smb_ff]= pd.to_numeric(FFFFmonthly[smb_ff] , errors='coerce')\n",
        "FFFFmonthly[hml_ff]= pd.to_numeric(FFFFmonthly[hml_ff] , errors='coerce')\n"
      ],
      "metadata": {
        "id": "nFLHGYsftZuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15:42\n",
        "#add month and year columns to factors and FFFFmonthly\n",
        "FF=FFFFmonthly\n",
        "\n",
        "factors['date']= pd.to_datetime(factors[['date']])\n",
        "factors['month']= factors['date'].dt.month\n",
        "factors['year']= factors['year'].dt.year\n",
        "\n",
        "FF['month']= \"\"\n",
        "for i in FF.index:\n",
        "  #take last two digits of date (ie take the month)\n",
        "  FF['month'][i]= int(str(FF['date'][i][-2]+ str(FF['date'][i][-1])))\n",
        "\n",
        "\n",
        "FF['year']= \"\"\n",
        "for i in FF.index:\n",
        "  #int(str) function takes the string and turns it into an integer\n",
        "  #take first 4 digits of date (ie take the year characters)\n",
        "  FF['year'][i]= int(str(FF['date'][i][0:4]))\n"
      ],
      "metadata": {
        "id": "KFGh2jxFuAmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#15:55\n",
        "#merdge FF INTO factors\n",
        "\n",
        "#order correct?\n",
        "factors.join(FF, on= 'month' and 'year', how='left')\n",
        "\n",
        "print(factors)\n"
      ],
      "metadata": {
        "id": "lqsgyQIgwJjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FF vs factors"
      ],
      "metadata": {
        "id": "hQKRtITyw8o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#16:24\n",
        "\n",
        "#various percentiles print\n",
        "factors.describe(percentiles=[0.1, .25, .5, .75, .9])\n",
        "\n"
      ],
      "metadata": {
        "id": "a-aXDreMxHbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16:30\n",
        "#KS tests\n",
        "#KS tests (one-sample) if a dataset has a normal distrobution,\n",
        " #(two-sample) if two datasets have similar distrobutions\n",
        " #results are (d,f), d being the maximum difference in values, other is p-value\n",
        "\n",
        "ks_2samp(factors['mkt'], FF['mkt_ff'])\n",
        "\n",
        "\n",
        "ks_2samp(factors['smb'], FF['smb_ff'])\n",
        "\n",
        "\n",
        "ks_2samp(factors['hml'], FF['hml_ff'])\n",
        "\n"
      ],
      "metadata": {
        "id": "EJ22WKHjxYSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#16:44\n",
        "#compute correlation\n",
        "\n",
        "factors.corr(method='pearson')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xm4mivEhYRgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sv_Wdm6axGRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODS to three factor"
      ],
      "metadata": {
        "id": "jtgTsakAPO4x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JCda-R-HN-c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#merdge crsp and compustat data"
      ],
      "metadata": {
        "id": "N5VlZtpB5J6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTOtumOZoAMQ"
      },
      "outputs": [],
      "source": [
        "#2:58\n",
        "#clean CRSP/compustat merged datafram\n",
        "\n",
        "#parse? relevant variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3:11\n",
        "#convert variables pd.to_numeric"
      ],
      "metadata": {
        "id": "hdoYne1Z7uM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate vales for each collum (make calulated collum?)"
      ],
      "metadata": {
        "id": "tLz_MUwDoKp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#table 1\n",
        "#summary stat for each"
      ],
      "metadata": {
        "id": "T3jev1kCoRNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#table 2\n",
        "#correlatin table for all factors"
      ],
      "metadata": {
        "id": "kmp54aOUocBm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}