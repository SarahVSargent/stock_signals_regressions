{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahVSargent/stock_signals_regressions/blob/main/PEAD_Post_Earnings_Announcement_Drift.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnM-8jL14k1U"
      },
      "outputs": [],
      "source": [
        "#author: SarahVSargent\n",
        "#barnard and thomas 1989\n",
        "#drift before and after earnings announcement\n",
        "\n",
        "\n",
        "#how to prove drift is uncorrelated to sloane?- regression to see correlation, intercept is significat and nonzero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI2LcNG68zww"
      },
      "outputs": [],
      "source": [
        "#ar= abnormal returns, difference between raw return of firm on day x and mean return of firms from same size decile on same day\n",
        "#car= cumulatibve abnormal return, from days a to b, ar is abnormal return of one day\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1omnoSsDi0a",
        "outputId": "8757a861-600d-49d9-939d-55752053da33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#16:46\n",
        "#coonnect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgfR6Pg9DsjB",
        "outputId": "b2544517-92c3-42e0-9bc7-bc955812f8ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandasql\n",
            "  Downloading pandasql-0.7.3.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pandasql) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pandasql) (1.5.3)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from pandasql) (2.0.20)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandasql) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pandasql) (2023.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->pandasql) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->pandasql) (2.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.16.0)\n",
            "Building wheels for collected packages: pandasql\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-py3-none-any.whl size=26771 sha256=5c0e0dd612513df26e9ae0eed0259d8f92f6ef4c6770a5815c7f5b743326834c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/bc/3a/8434bdcccf5779e72894a9b24fecbdcaf97940607eaf4bcdf9\n",
            "Successfully built pandasql\n",
            "Installing collected packages: pandasql\n",
            "Successfully installed pandasql-0.7.3\n"
          ]
        }
      ],
      "source": [
        "# Import tools\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "!pip install pandasql\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from scipy.stats.mstats import winsorize\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import seaborn as sns\n",
        "import pandasql as ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IorMnYHRA4Gn",
        "outputId": "8c4f98c7-7246-4dfb-abeb-ab4e28dc11a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-46e49c2f28c0>:5: DtypeWarning: Columns (49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  c = pd.read_csv(file, usecols= columnstouse)[columnstouse]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['TICKER', 'date', 'SHRCD', 'EXCHCD', 'RET'], dtype='object')\n",
            "         TICKER      date  SHRCD  EXCHCD        RET\n",
            "0          EGAS  20150102   11.0     2.0   0.000000\n",
            "1          EGAS  20150105   11.0     2.0   0.000000\n",
            "2          EGAS  20150106   11.0     2.0  -0.010889\n",
            "3          EGAS  20150107   11.0     2.0   0.001835\n",
            "4          EGAS  20150108   11.0     2.0   0.005494\n",
            "...         ...       ...    ...     ...        ...\n",
            "13967877   TSLA  20220325   11.0     3.0  -0.003235\n",
            "13967878   TSLA  20220328   11.0     3.0   0.080345\n",
            "13967879   TSLA  20220329   11.0     3.0    0.00708\n",
            "13967880   TSLA  20220330   11.0     3.0  -0.005075\n",
            "13967881   TSLA  20220331   11.0     3.0  -0.014982\n",
            "\n",
            "[13967882 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#16:45smth\n",
        "file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD/CRSPDaily2015to20220331.csv\"\n",
        "#only use specific columns\n",
        "columnstouse= ['TICKER', 'date', 'SHRCD', 'EXCHCD','RET']\n",
        "c = pd.read_csv(file, usecols= columnstouse)[columnstouse]\n",
        "print(c.columns)\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_pqx4-Ws-cHw",
        "outputId": "9da75c11-9a6c-4ee1-c20d-01ea96352f99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(13967882, 5)\n"
          ]
        }
      ],
      "source": [
        "print(c.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "v7HwK_77DvoD",
        "outputId": "410d80ad-278b-45b6-bf77-2f81be125a5b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-7-06291d5798e0>:2: DtypeWarning: Columns (5,9,18,49,57) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  b = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['PERMNO', 'date', 'NAMEENDT', 'SHRCD', 'EXCHCD', 'SICCD', 'NCUSIP',\n",
            "       'TICKER', 'COMNAM', 'SHRCLS', 'TSYMBOL', 'NAICS', 'PRIMEXCH', 'TRDSTAT',\n",
            "       'SECSTAT', 'PERMCO', 'ISSUNO', 'HEXCD', 'HSICCD', 'CUSIP', 'DCLRDT',\n",
            "       'DLAMT', 'DLPDT', 'DLSTCD', 'NEXTDT', 'PAYDT', 'RCRDDT', 'SHRFLG',\n",
            "       'HSICMG', 'HSICIG', 'DISTCD', 'DIVAMT', 'FACPR', 'FACSHR', 'ACPERM',\n",
            "       'ACCOMP', 'SHRENDDT', 'NWPERM', 'DLRETX', 'DLPRC', 'DLRET', 'TRTSCD',\n",
            "       'NMSIND', 'MMCNT', 'NSDINX', 'BIDLO', 'ASKHI', 'PRC', 'VOL', 'RET',\n",
            "       'BID', 'ASK', 'SHROUT', 'CFACPR', 'CFACSHR', 'OPENPRC', 'NUMTRD',\n",
            "       'RETX', 'vwretd', 'vwretx', 'ewretd', 'ewretx', 'sprtrn'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Ertimur replication/CRSP2020Through2022Daily.csv\"\n",
        "b = pd.read_csv(file)\n",
        "print(b.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ODkhIyGTGfFO"
      },
      "outputs": [],
      "source": [
        "# file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD/CRSPMonthly2015to20220331.csv\"\n",
        "# d = pd.read_csv(file)\n",
        "# print(d.columns)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wqOyiFW2Dx4n"
      },
      "outputs": [],
      "source": [
        "# file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD/IBESSummaryStatistics1976Through20220601.csv\"\n",
        "# g = pd.read_csv(file)\n",
        "# print(g.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xPFTMA40DzcM",
        "outputId": "551ef3b1-93d5-4f89-bdd7-2fc7f89bfd6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "imported\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"imported\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-12fV5gEVhl"
      },
      "source": [
        "clean CRSP data (which one?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bMPaCg8ZmJmZ"
      },
      "outputs": [],
      "source": [
        "#import df\n",
        "z=c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ifx4tnngAQgv",
        "outputId": "3dbece24-eaeb-41da-dded-67ae03084777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         TICKER      date SHRCD EXCHCD        RET\n",
            "0          EGAS  20150102  11.0    2.0   0.000000\n",
            "1          EGAS  20150105  11.0    2.0   0.000000\n",
            "2          EGAS  20150106  11.0    2.0  -0.010889\n",
            "3          EGAS  20150107  11.0    2.0   0.001835\n",
            "4          EGAS  20150108  11.0    2.0   0.005494\n",
            "...         ...       ...   ...    ...        ...\n",
            "13967877   TSLA  20220325  11.0    3.0  -0.003235\n",
            "13967878   TSLA  20220328  11.0    3.0   0.080345\n",
            "13967879   TSLA  20220329  11.0    3.0    0.00708\n",
            "13967880   TSLA  20220330  11.0    3.0  -0.005075\n",
            "13967881   TSLA  20220331  11.0    3.0  -0.014982\n",
            "\n",
            "[13967882 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#17:18\n",
        "z.columns= [['TICKER', 'date', 'SHRCD', 'EXCHCD','RET']]\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G-i0oA_Y8Isc",
        "outputId": "85c8081f-6c3f-4fa6-fbbb-58f8f181f764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           tic      date  shrcd  exchcd        ret\n",
            "0         EGAS  20150102   11.0     2.0   0.000000\n",
            "1         EGAS  20150105   11.0     2.0   0.000000\n",
            "2         EGAS  20150106   11.0     2.0  -0.010889\n",
            "3         EGAS  20150107   11.0     2.0   0.001835\n",
            "4         EGAS  20150108   11.0     2.0   0.005494\n",
            "...        ...       ...    ...     ...        ...\n",
            "13967877  TSLA  20220325   11.0     3.0  -0.003235\n",
            "13967878  TSLA  20220328   11.0     3.0   0.080345\n",
            "13967879  TSLA  20220329   11.0     3.0    0.00708\n",
            "13967880  TSLA  20220330   11.0     3.0  -0.005075\n",
            "13967881  TSLA  20220331   11.0     3.0  -0.014982\n",
            "\n",
            "[13967882 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#rename columns,  order matter if empty df\n",
        "z.columns = ['tic', 'date', 'shrcd', 'exchcd','ret']\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DZOXOY5T71GS"
      },
      "outputs": [],
      "source": [
        "z['tic'] = z['tic'].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qrMyPDZtEmd1",
        "outputId": "9895b2c9-6591-472f-8c04-b555f833128d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           tic       date  shrcd  exchcd       ret\n",
            "0         EGAS 2015-01-02   11.0     2.0  0.000000\n",
            "1         EGAS 2015-01-05   11.0     2.0  0.000000\n",
            "2         EGAS 2015-01-06   11.0     2.0 -0.010889\n",
            "3         EGAS 2015-01-07   11.0     2.0  0.001835\n",
            "4         EGAS 2015-01-08   11.0     2.0  0.005494\n",
            "...        ...        ...    ...     ...       ...\n",
            "13967877  TSLA 2022-03-25   11.0     3.0 -0.003235\n",
            "13967878  TSLA 2022-03-28   11.0     3.0  0.080345\n",
            "13967879  TSLA 2022-03-29   11.0     3.0  0.007080\n",
            "13967880  TSLA 2022-03-30   11.0     3.0 -0.005075\n",
            "13967881  TSLA 2022-03-31   11.0     3.0 -0.014982\n",
            "\n",
            "[13967882 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "#17:18\n",
        "#z['tic'] = z['TICKER'].apply(str)\n",
        "#z['tic']= z['TICKER'].astype(str)\n",
        "\n",
        "#z['date']= z['date'].strftime('%Y%m%d')\n",
        "#z['date']= pd.to_datetime(z['date'], format= '%Y%m%d')\n",
        "z['date'] = pd.to_datetime(z['date'], format='%Y%m%d')\n",
        "# z['date'] = z['date'].astype(object)\n",
        "# z['date'] = z['date'].apply(lambda x: pd.to_datetime(str(x), format='%Y%m%d'))\n",
        "\n",
        "z['shrcd']= pd.to_numeric(z['shrcd'], errors= 'coerce')\n",
        "z['ret']= pd.to_numeric(z['ret'], errors= 'coerce')\n",
        "z['exchcd']= pd.to_numeric(z['exchcd'],errors= 'coerce')\n",
        "print(z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FNhor66n8LKv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rRlJi6Ly8L6f",
        "outputId": "d7454f1c-d852-4ab0-cf61-f3fa5c852fa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         tic       date  shrcd  exchcd       ret\n",
            "0          A 2019-01-02   11.0     1.0 -0.026238\n",
            "1          A 2019-01-03   11.0     1.0 -0.036840\n",
            "2          A 2019-01-04   11.0     1.0  0.034614\n",
            "3          A 2019-01-07   11.0     1.0  0.021234\n",
            "4          A 2019-01-08   11.0     1.0  0.014660\n",
            "...      ...        ...    ...     ...       ...\n",
            "1121427  ZUO 2022-03-25   11.0     1.0 -0.026025\n",
            "1121428  ZUO 2022-03-28   11.0     1.0  0.008016\n",
            "1121429  ZUO 2022-03-29   11.0     1.0  0.029158\n",
            "1121430  ZUO 2022-03-30   11.0     1.0 -0.037347\n",
            "1121431  ZUO 2022-03-31   11.0     1.0  0.002007\n",
            "\n",
            "[1121432 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "z = z[z['date'] >= \"2019-01-01\"]\n",
        "\n",
        "z = z[(z['shrcd']==10) | (z['shrcd']==11)]\n",
        "\n",
        "z = z[(z['exchcd']==1) | (z['exchcd']==31) | (z['exchcd']==2) | (z['exchcd']==32)]\n",
        "\n",
        "z = z.groupby('tic').filter(lambda x: len(x) >= 252)\n",
        "\n",
        "z = z.sort_values(by = ['tic', 'date'], ascending = True)\n",
        "\n",
        "z.replace([np.inf , -np.inf], np.nan, inplace = True)\n",
        "\n",
        "z = z.dropna()\n",
        "\n",
        "z = z.reset_index()\n",
        "z.drop('index', inplace = True, axis = 1)\n",
        "\n",
        "z2019 = z\n",
        "\n",
        "print(z2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZG5prFWVFQoL"
      },
      "outputs": [],
      "source": [
        "# z2019= z[z['date'] >= \"2019-01-01\"]\n",
        "\n",
        "# z2019= z2019[(z2019['shrcd'] == 10) | (z2019['shrcd'] == 11)]\n",
        "# z2019= z2019[(z2019['exchcd'] == 1) | (z2019['exchcd'] == 2)| (z2019['exchcd'] == 31) | (z2019['exchcd'] == 32)]\n",
        "\n",
        "# #what doing here?\n",
        "# z2019= z2019.groupby('tic').filter(lambda x: len(x)> 252)\n",
        "\n",
        "# z2019= z2019.sort_values(by=['tic', 'date'], ascending= True)\n",
        "# #dont do z2019=  because inplace= true\n",
        "# z2019.replace([np.inf, -np.inf], np.nan, inplace= True)\n",
        "# z2019= z2019.dropna()\n",
        "# #reset index, reindex\n",
        "# z2019= z2019.reset_index()\n",
        "# z2019.drop('index', inplace=True, axis=1)\n",
        "\n",
        "# print(z2019)\n",
        "# print(z2019.columns)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COmziDVaIENF"
      },
      "source": [
        "compustat import and clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zjOa8iAYIG5K",
        "outputId": "85535b82-2d2c-4745-f8f8-f3aad414e79d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-e0a88803e4c9>:2: DtypeWarning: Columns (17,18,26,30,647,669,674) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  a = pd.read_csv(file)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['gvkey', 'datadate', 'fyearq', 'fqtr', 'fyr', 'indfmt', 'consol',\n",
            "       'popsrc', 'datafmt', 'tic',\n",
            "       ...\n",
            "       'priusa', 'sic', 'spcindcd', 'spcseccd', 'spcsrc', 'state', 'stko',\n",
            "       'weburl', 'dldte', 'ipodate'],\n",
            "      dtype='object', length=680)\n"
          ]
        }
      ],
      "source": [
        "file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Ertimur replication/Compustat2018Through2022.csv\"\n",
        "a = pd.read_csv(file)\n",
        "print(a.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LCnP_ZSyII7B"
      },
      "outputs": [],
      "source": [
        "y2018= a\n",
        "#dont rename columns to an unreadable letter, code readability matters\n",
        "#turn on high ram when importing/ always\n",
        "#df.columns['a'] renames columns in that order, so make sure order is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_S6dNU4hIOnJ",
        "outputId": "baa5b362-199f-4146-fefc-86e191a394e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          tic  datadate  fyearq  fqtr         rdq     cshoq    prccq\n",
            "0         AIR  20180228    2017   3.0  20180320.0    34.639  42.5800\n",
            "1         AIR  20180531    2017   4.0  20180710.0    34.716  44.6900\n",
            "2         AIR  20180831    2018   1.0  20180925.0    35.041  46.6700\n",
            "3         AIR  20181130    2018   2.0  20181218.0    35.095  43.6900\n",
            "4         AIR  20190228    2018   3.0  20190319.0    35.067  36.5300\n",
            "...       ...       ...     ...   ...         ...       ...      ...\n",
            "190780  DTRUY  20201231    2020   4.0  20211126.0       NaN      NaN\n",
            "190781  DTRUY  20210331    2021   1.0         NaN       NaN      NaN\n",
            "190782  DTRUY  20210630    2021   2.0         NaN       NaN      NaN\n",
            "190783  DTRUY  20210930    2021   3.0  20211126.0  1645.904      NaN\n",
            "190784  DTRUY  20211231    2021   4.0  20220324.0  1645.904  18.4389\n",
            "\n",
            "[190785 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "#17:28\n",
        "\n",
        "#y2018.columns= [['tic', 'datadate', 'fyearq', 'fqtr', 'rdq', 'cshoq', 'prccq']]\n",
        "#y2018 = y2018.reindex(['tic', 'datadate', 'fyearq', 'fqtr', 'rdq', 'cshoq', 'prccq'])\n",
        "y2018= y2018[['tic', 'datadate', 'fyearq', 'fqtr', 'rdq', 'cshoq', 'prccq']]\n",
        "print(y2018)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3FXL50LeInMt",
        "outputId": "21438f6f-6cf3-4fb1-bdce-6b2084cb7d52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-4251068f97e6>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y2018.replace([np.inf, -np.inf], np.nan, inplace= True)\n"
          ]
        }
      ],
      "source": [
        "y2018.replace([np.inf, -np.inf], np.nan, inplace= True)\n",
        "y2018= y2018.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EQFHXhNOIp3_",
        "outputId": "4142437b-7cfe-41c2-d459-6bd51fabb944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          tic   datadate  fyearq  fqtr         rdq     cshoq    prccq\n",
            "0         AIR 2018-02-28    2017   3.0  20180320.0    34.639  42.5800\n",
            "1         AIR 2018-05-31    2017   4.0  20180710.0    34.716  44.6900\n",
            "2         AIR 2018-08-31    2018   1.0  20180925.0    35.041  46.6700\n",
            "3         AIR 2018-11-30    2018   2.0  20181218.0    35.095  43.6900\n",
            "4         AIR 2019-02-28    2018   3.0  20190319.0    35.067  36.5300\n",
            "...       ...        ...     ...   ...         ...       ...      ...\n",
            "190742   IBRX 2021-12-31    2021   4.0  20220301.0   397.830   6.0800\n",
            "190743   IBRX 2022-03-31    2022   1.0  20220510.0   397.830   5.6100\n",
            "190760   NXTP 2021-08-31    2021   2.0  20211020.0    89.694   2.0000\n",
            "190761   NXTP 2021-11-30    2021   3.0  20220113.0   109.247   1.0600\n",
            "190784  DTRUY 2021-12-31    2021   4.0  20220324.0  1645.904  18.4389\n",
            "\n",
            "[114416 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "y2018['tic']= y2018['tic'].astype(str)\n",
        "y2018['datadate']= pd.to_datetime(y2018['datadate'], format= '%Y%m%d')\n",
        "y2018['fyearq']= pd.to_numeric(y2018['fyearq'], errors= 'coerce')\n",
        "y2018['fqtr']= pd.to_numeric(y2018['fqtr'], errors= 'coerce')\n",
        "y2018['rdq']= pd.to_numeric(y2018['rdq'],errors= 'coerce')\n",
        "y2018['cshoq']= pd.to_numeric(y2018['cshoq'], errors= 'coerce')\n",
        "y2018['prccq']= pd.to_numeric(y2018['prccq'],errors= 'coerce')\n",
        "print(y2018)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y3xQ6x19JQlH",
        "outputId": "7d446610-ef79-4a8e-fa0c-23b259e62e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         tic   datadate  fyearq  fqtr         rdq  market_value\n",
            "0          A 2019-01-31    2019   1.0  20190220.0  24183.900000\n",
            "1          A 2019-04-30    2019   2.0  20190514.0  24883.793500\n",
            "2          A 2019-07-31    2019   3.0  20190814.0  21489.127770\n",
            "3          A 2019-10-31    2019   4.0  20191125.0  23412.128250\n",
            "4          A 2020-01-31    2020   1.0  20200218.0  25597.562880\n",
            "...      ...        ...     ...   ...         ...           ...\n",
            "86142  ZZZOF 2020-11-30    2020   3.0  20210127.0      1.939570\n",
            "86143  ZZZOF 2021-02-28    2020   4.0  20210630.0      4.848925\n",
            "86144  ZZZOF 2021-05-31    2021   1.0  20210729.0      2.134000\n",
            "86145  ZZZOF 2021-08-31    2021   2.0  20211027.0      1.358000\n",
            "86146  ZZZOF 2021-11-30    2021   3.0  20220127.0      1.008800\n",
            "\n",
            "[86147 rows x 6 columns]\n",
            "Index(['tic', 'datadate', 'fyearq', 'fqtr', 'rdq', 'market_value'], dtype='object')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-23-25e8099bb40e>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y2019['market_value'] = y2019['cshoq'] * y2019['prccq']\n"
          ]
        }
      ],
      "source": [
        "y2019= y2018[y2018['datadate'] >= \"2019-01-01\"]\n",
        "\n",
        "#add market value\n",
        "y2019['market_value'] = y2019['cshoq'] * y2019['prccq']\n",
        "\n",
        "y2019= y2019.sort_values(by=['tic', 'datadate'], ascending= True)\n",
        "y2019.replace([np.inf, -np.inf], np.nan, inplace= True)\n",
        "y2019= y2019.dropna()\n",
        "\n",
        "y2019.drop('cshoq', inplace=True, axis=1)\n",
        "y2019.drop('prccq', inplace=True, axis=1)\n",
        "#reset index, reindex\n",
        "y2019= y2019.reset_index()\n",
        "y2019.drop('index', inplace=True, axis=1)\n",
        "\n",
        "print(y2019)\n",
        "print(y2019.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8WGpyxZyUlFv"
      },
      "outputs": [],
      "source": [
        "# prompt: rename rdq to date in df\n",
        "\n",
        "y2019.rename(columns={'rdq': 'date'}, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MyMPe3eOAC7F",
        "outputId": "fe913088-e2eb-4780-fc00-b4c6004d7e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         tic   datadate  fyearq  fqtr        date  market_value\n",
            "0          A 2019-01-31    2019   1.0  20190220.0  24183.900000\n",
            "1          A 2019-04-30    2019   2.0  20190514.0  24883.793500\n",
            "2          A 2019-07-31    2019   3.0  20190814.0  21489.127770\n",
            "3          A 2019-10-31    2019   4.0  20191125.0  23412.128250\n",
            "4          A 2020-01-31    2020   1.0  20200218.0  25597.562880\n",
            "...      ...        ...     ...   ...         ...           ...\n",
            "86142  ZZZOF 2020-11-30    2020   3.0  20210127.0      1.939570\n",
            "86143  ZZZOF 2021-02-28    2020   4.0  20210630.0      4.848925\n",
            "86144  ZZZOF 2021-05-31    2021   1.0  20210729.0      2.134000\n",
            "86145  ZZZOF 2021-08-31    2021   2.0  20211027.0      1.358000\n",
            "86146  ZZZOF 2021-11-30    2021   3.0  20220127.0      1.008800\n",
            "\n",
            "[86147 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "print(y2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RdeG6xQsiJ4d",
        "outputId": "f25b6e98-bcd8-4ad2-a025-e095935667d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         tic   datadate  fyearq  fqtr       date  market_value\n",
            "0          A 2019-01-31    2019   1.0 2019-02-20  24183.900000\n",
            "1          A 2019-04-30    2019   2.0 2019-05-14  24883.793500\n",
            "2          A 2019-07-31    2019   3.0 2019-08-14  21489.127770\n",
            "3          A 2019-10-31    2019   4.0 2019-11-25  23412.128250\n",
            "4          A 2020-01-31    2020   1.0 2020-02-18  25597.562880\n",
            "...      ...        ...     ...   ...        ...           ...\n",
            "86142  ZZZOF 2020-11-30    2020   3.0 2021-01-27      1.939570\n",
            "86143  ZZZOF 2021-02-28    2020   4.0 2021-06-30      4.848925\n",
            "86144  ZZZOF 2021-05-31    2021   1.0 2021-07-29      2.134000\n",
            "86145  ZZZOF 2021-08-31    2021   2.0 2021-10-27      1.358000\n",
            "86146  ZZZOF 2021-11-30    2021   3.0 2022-01-27      1.008800\n",
            "\n",
            "[86147 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "y2019['date']= pd.to_datetime(y2019['date'], format= \"%Y%m%d\")\n",
        "print(y2019)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y6nCL0ssEH8K",
        "outputId": "57ea19a3-1988-4d16-fbf8-18afd22266e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         tic       date  shrcd  exchcd       ret\n",
            "0          A 2019-01-02   11.0     1.0 -0.026238\n",
            "1          A 2019-01-03   11.0     1.0 -0.036840\n",
            "2          A 2019-01-04   11.0     1.0  0.034614\n",
            "3          A 2019-01-07   11.0     1.0  0.021234\n",
            "4          A 2019-01-08   11.0     1.0  0.014660\n",
            "...      ...        ...    ...     ...       ...\n",
            "1121427  ZUO 2022-03-25   11.0     1.0 -0.026025\n",
            "1121428  ZUO 2022-03-28   11.0     1.0  0.008016\n",
            "1121429  ZUO 2022-03-29   11.0     1.0  0.029158\n",
            "1121430  ZUO 2022-03-30   11.0     1.0 -0.037347\n",
            "1121431  ZUO 2022-03-31   11.0     1.0  0.002007\n",
            "\n",
            "[1121432 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "print(z2019)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfvil2HKLh7-"
      },
      "source": [
        "merdge crsp and compustat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZtB2GG8fAMWU",
        "outputId": "12cdf9d6-d490-4ca7-cd95-b5062567bd41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         tic       date  shrcd  exchcd       ret datadate  fyearq  fqtr  \\\n",
            "0          A 2019-01-02   11.0     1.0 -0.026238      NaT     NaN   NaN   \n",
            "1          A 2019-01-03   11.0     1.0 -0.036840      NaT     NaN   NaN   \n",
            "2          A 2019-01-04   11.0     1.0  0.034614      NaT     NaN   NaN   \n",
            "3          A 2019-01-07   11.0     1.0  0.021234      NaT     NaN   NaN   \n",
            "4          A 2019-01-08   11.0     1.0  0.014660      NaT     NaN   NaN   \n",
            "...      ...        ...    ...     ...       ...      ...     ...   ...   \n",
            "1121438  ZUO 2022-03-25   11.0     1.0 -0.026025      NaT     NaN   NaN   \n",
            "1121439  ZUO 2022-03-28   11.0     1.0  0.008016      NaT     NaN   NaN   \n",
            "1121440  ZUO 2022-03-29   11.0     1.0  0.029158      NaT     NaN   NaN   \n",
            "1121441  ZUO 2022-03-30   11.0     1.0 -0.037347      NaT     NaN   NaN   \n",
            "1121442  ZUO 2022-03-31   11.0     1.0  0.002007      NaT     NaN   NaN   \n",
            "\n",
            "         market_value  \n",
            "0                 NaN  \n",
            "1                 NaN  \n",
            "2                 NaN  \n",
            "3                 NaN  \n",
            "4                 NaN  \n",
            "...               ...  \n",
            "1121438           NaN  \n",
            "1121439           NaN  \n",
            "1121440           NaN  \n",
            "1121441           NaN  \n",
            "1121442           NaN  \n",
            "\n",
            "[1121443 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "#left join TBD\n",
        "maindf= z2019.merge(y2019, how= 'left', on=['tic', 'date'])\n",
        "print(maindf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6Qf7xI54LfZa",
        "outputId": "91b52334-6550-4db2-9e36-db1fb3fa6a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['tic', 'date', 'shrcd', 'exchcd', 'ret', 'datadate', 'fyearq', 'fqtr',\n",
            "       'market_value', 'year', 'qtr'],\n",
            "      dtype='object')\n",
            "         tic       date  shrcd  exchcd       ret datadate  fyearq  fqtr  \\\n",
            "0          A 2019-01-02   11.0     1.0 -0.026238      NaT     NaN   NaN   \n",
            "1          A 2019-01-03   11.0     1.0 -0.036840      NaT     NaN   NaN   \n",
            "2          A 2019-01-04   11.0     1.0  0.034614      NaT     NaN   NaN   \n",
            "3          A 2019-01-07   11.0     1.0  0.021234      NaT     NaN   NaN   \n",
            "4          A 2019-01-08   11.0     1.0  0.014660      NaT     NaN   NaN   \n",
            "...      ...        ...    ...     ...       ...      ...     ...   ...   \n",
            "1121438  ZUO 2022-03-25   11.0     1.0 -0.026025      NaT     NaN   NaN   \n",
            "1121439  ZUO 2022-03-28   11.0     1.0  0.008016      NaT     NaN   NaN   \n",
            "1121440  ZUO 2022-03-29   11.0     1.0  0.029158      NaT     NaN   NaN   \n",
            "1121441  ZUO 2022-03-30   11.0     1.0 -0.037347      NaT     NaN   NaN   \n",
            "1121442  ZUO 2022-03-31   11.0     1.0  0.002007      NaT     NaN   NaN   \n",
            "\n",
            "         market_value  year  qtr  \n",
            "0                 NaN  2019  1.0  \n",
            "1                 NaN  2019  1.0  \n",
            "2                 NaN  2019  1.0  \n",
            "3                 NaN  2019  1.0  \n",
            "4                 NaN  2019  1.0  \n",
            "...               ...   ...  ...  \n",
            "1121438           NaN  2022  1.0  \n",
            "1121439           NaN  2022  1.0  \n",
            "1121440           NaN  2022  1.0  \n",
            "1121441           NaN  2022  1.0  \n",
            "1121442           NaN  2022  1.0  \n",
            "\n",
            "[1121443 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#add calander year column\n",
        "#changed from to numeric to to datetime\n",
        "maindf['date']= pd.to_datetime(maindf['date'], errors= 'coerce')\n",
        "maindf['year']= maindf['date'].dt.year\n",
        "\n",
        "#not needed\n",
        "# #add calander quarter column\n",
        "# maindf['quarter']= maindf['date'].dt.quarter\n",
        "\n",
        "#add calander month column\n",
        "#ceil truncated number\n",
        "maindf['qtr']= np.ceil(maindf['date'].dt.month/3)\n",
        "\n",
        "print(maindf.columns)\n",
        "print(maindf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3QlAvNYMZI0"
      },
      "source": [
        "add size deciles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h3fQqJ2lEMrs",
        "outputId": "0ac1cbba-27e8-458a-dac5-73d135db80bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         tic       date  shrcd  exchcd       ret   datadate  fyearq  fqtr  \\\n",
            "33         A 2019-02-20   11.0     1.0  0.013416 2019-01-31  2019.0   1.0   \n",
            "91         A 2019-05-14   11.0     1.0  0.029388 2019-04-30  2019.0   2.0   \n",
            "155        A 2019-08-14   11.0     1.0 -0.030308 2019-07-31  2019.0   3.0   \n",
            "227        A 2019-11-25   11.0     1.0  0.014408 2019-10-31  2019.0   4.0   \n",
            "283        A 2020-02-18   11.0     1.0 -0.012002 2020-01-31  2020.0   1.0   \n",
            "...      ...        ...    ...     ...       ...        ...     ...   ...   \n",
            "1121175  ZUO 2021-03-11   11.0     1.0  0.059930 2021-01-31  2020.0   4.0   \n",
            "1121228  ZUO 2021-05-26   11.0     1.0  0.017591 2021-04-30  2021.0   1.0   \n",
            "1121291  ZUO 2021-08-25   11.0     1.0 -0.001222 2021-07-31  2021.0   2.0   \n",
            "1121359  ZUO 2021-12-01   11.0     1.0 -0.069157 2021-10-31  2021.0   3.0   \n",
            "1121421  ZUO 2022-03-02   11.0     1.0  0.012492 2022-01-31  2021.0   4.0   \n",
            "\n",
            "         market_value  year  qtr  \n",
            "33        24183.90000  2019  1.0  \n",
            "91        24883.79350  2019  2.0  \n",
            "155       21489.12777  2019  3.0  \n",
            "227       23412.12825  2019  4.0  \n",
            "283       25597.56288  2020  1.0  \n",
            "...               ...   ...  ...  \n",
            "1121175    1783.33400  2021  1.0  \n",
            "1121228    1979.70480  2021  2.0  \n",
            "1121291    2151.48115  2021  3.0  \n",
            "1121359    2763.25702  2021  4.0  \n",
            "1121421    2129.57128  2022  1.0  \n",
            "\n",
            "[15634 rows x 11 columns]\n"
          ]
        }
      ],
      "source": [
        "#5\n",
        "onerdq= maindf.dropna()\n",
        "\n",
        "print(onerdq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T7YT_aawEPxa",
        "outputId": "a5fe8bb5-91ab-4e1d-b5a2-c98eda96090a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      year   tic   market_value\n",
            "0     2019     A   24183.900000\n",
            "1     2019    AA    5224.243200\n",
            "2     2019  AAMC      49.657044\n",
            "3     2019   AAP   12233.310610\n",
            "4     2019  ABBV  119131.200420\n",
            "...    ...   ...            ...\n",
            "5185  2022  ZDGE     108.864000\n",
            "5186  2022   ZEN   12681.455420\n",
            "5187  2022   ZOM     300.339350\n",
            "5188  2022   ZTS  115322.233220\n",
            "5189  2022   ZUO    2129.571280\n",
            "\n",
            "[5190 rows x 3 columns]\n",
            "Index(['year', 'tic', 'market_value'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#new df with only year and first market value\n",
        "marketvaluestartyear= onerdq.groupby(['year', 'tic'], as_index= False)['market_value'].first()\n",
        "\n",
        "\n",
        "print(marketvaluestartyear)\n",
        "print(marketvaluestartyear.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4fmCWZrTESkG",
        "outputId": "6a1bc771-b6a2-4195-f9f7-bc90fefdbb26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      year   tic   market_value  size_quantile\n",
            "0     2019     A   24183.900000       0.885580\n",
            "1     2019    AA    5224.243200       0.659875\n",
            "2     2019  AAMC      49.657044       0.061129\n",
            "3     2019   AAP   12233.310610       0.800940\n",
            "4     2019  ABBV  119131.200420       0.978056\n",
            "...    ...   ...            ...            ...\n",
            "5185  2022  ZDGE     108.864000       0.072917\n",
            "5186  2022   ZEN   12681.455420       0.741186\n",
            "5187  2022   ZOM     300.339350       0.135417\n",
            "5188  2022   ZTS  115322.233220       0.963141\n",
            "5189  2022   ZUO    2129.571280       0.377404\n",
            "\n",
            "[5190 rows x 4 columns]\n",
            "Index(['year', 'tic', 'market_value', 'size_quantile'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#new column with size quantile for each firm, pct is percentile rank, using marketing value in a specific year\n",
        "marketvaluestartyear['size_quantile']= marketvaluestartyear.groupby(['year'])['market_value'].rank(pct= True)\n",
        "\n",
        "\n",
        "print(marketvaluestartyear)\n",
        "print(marketvaluestartyear.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hI3Hxbe4Madi",
        "outputId": "3b8f0e62-01c3-4a4c-8bd1-c42bf76b9a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      year   tic   market_value  size_quantile  size_decile\n",
            "0     2019     A   24183.900000       0.885580          1.0\n",
            "1     2019    AA    5224.243200       0.659875          1.0\n",
            "2     2019  AAMC      49.657044       0.061129          1.0\n",
            "3     2019   AAP   12233.310610       0.800940          1.0\n",
            "4     2019  ABBV  119131.200420       0.978056          1.0\n",
            "...    ...   ...            ...            ...          ...\n",
            "5185  2022  ZDGE     108.864000       0.072917          1.0\n",
            "5186  2022   ZEN   12681.455420       0.741186          1.0\n",
            "5187  2022   ZOM     300.339350       0.135417          1.0\n",
            "5188  2022   ZTS  115322.233220       0.963141          1.0\n",
            "5189  2022   ZUO    2129.571280       0.377404          1.0\n",
            "\n",
            "[5190 rows x 5 columns]\n",
            "Index(['year', 'tic', 'market_value', 'size_quantile', 'size_decile'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#quaantiles (percentiles) to deciles\n",
        "marketvaluestartyear['size_decile']= np.ceil(marketvaluestartyear['size_quantile']/10)\n",
        "\n",
        "\n",
        "\n",
        "print(marketvaluestartyear)\n",
        "#CHECK VALUES TO MAKE SURE PERCENTILES CONVERTED CORRECTLY\n",
        "print(marketvaluestartyear.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3YE5Prf9fFde",
        "outputId": "0054508b-2de8-4e22-f855-9a1e7311b0e8"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-b40dec4ca498>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    maindf= maindf.merge(marketvaluestartyear, on= 'tic', 'year', how= 'left')\u001b[0m\n\u001b[0m                                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ],
      "source": [
        "#5\n",
        "#left join merdge into maindf\n",
        "maindf= maindf.merge(marketvaluestartyear, on= 'tic', 'year', how= 'left')\n",
        "\n",
        "print(maindf.columns)\n",
        "print(maindf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5wMembEifZRC"
      },
      "outputs": [],
      "source": [
        "#6\n",
        "\n",
        "#calculate abnormal returns\n",
        "\n",
        "#same size decile, mean return\n",
        "maindf['date']= pd.to_datetime(maindf['date'])\n",
        "maindf['size_decile']= pd.to_numeric(maindf['size_decile'], errors= 'coerce')\n",
        "#new dataframe with calculated values- do we have to do this?, cant we just create a new calculated column and keep recorganizing based on groupby\n",
        "avgret= maindf.groupby()\n",
        "\n",
        "#complete\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QAZcY5uKkXbu"
      },
      "outputs": [],
      "source": [
        "#6\n",
        "maindf['ret']= pd.to_numeric(maindf['ret'], errors= 'coerce')\n",
        "maindf['avg_ret']= pd.to_numeric(maindf['avg_ret'], errors= 'coerce')\n",
        "maindf['abn_ret']= maindf['ret']- maindf['avg_ret']\n",
        "\n",
        "print(maindf.columns)\n",
        "print(maindf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REGsywOGl9oT"
      },
      "source": [
        "IBES surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "77n9nzbRk7V7"
      },
      "outputs": [],
      "source": [
        "file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD/IBESSurpriseHistory.csv\"\n",
        "e = pd.read_csv(file)\n",
        "print(e.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vXZWg12ymQyj"
      },
      "outputs": [],
      "source": [
        "ibes= e\n",
        "\n",
        "print(ibes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dYzc7RRJmVQe"
      },
      "outputs": [],
      "source": [
        "#7b\n",
        "#clean\n",
        "\n",
        "\n",
        "ibes['PYEAR']= pd.to_numeric(ibes['PYEAR'], errors= 'coerce')\n",
        "ibes['PMON']= pd.to_numeric(ibes['PMON'], errors= 'coerce')\n",
        "\n",
        "ibes= ibes[ibes['PYEAR'] >= \"2019\"]\n",
        "ibes= ibes[ibes['FISCALP'] == \"QTR\"]\n",
        "ibes= ibes[ibes['MEASURE'] == \"EPS\"]\n",
        "\n",
        "ibes= ibes.reset_index()\n",
        "ibes.drop('index', inplace=True, axis=1)\n",
        "\n",
        "print(ibes.columns)\n",
        "print(ibes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FFobL_fSneRB"
      },
      "outputs": [],
      "source": [
        "#datadate column add, last day of month\n",
        "\n",
        "#set to 1st of month\n",
        "ibes['PDAY']= 1\n",
        "ibes['datadate']= pd.to_datetime((10000*ibes['datadate']+ 100*ibes['PMON']+ ibes['PDAY']).astype(str), format='%Y%m%d')\n",
        "#last day of month - how?\n",
        "ibes['datadate']= pd.to_datetime((10000*ibes['datadate']+ 100*ibes['PMON']+ ibes['datadate']).astype(str), format='%Y%m%d')\n",
        "\n",
        "#parse\n",
        "ibes= ibes.filter(['OFTIC','PYEAR','PMON', 'suescore','datadate'])\n",
        "ibes= columns= ['tic', 'year', 'month', 'sue', 'datadate']\n",
        "\n",
        "ibes.replace([np.inf, -np.inf], np.nan, inplace= True)\n",
        "ibes= ibes.dropna()\n",
        "ibes= ibes.sort_values(by=['tic', 'datadate'], ascending= True)\n",
        "\n",
        "ibes= ibes.reset_index()\n",
        "ibes.drop('index', inplace=True, axis=1)\n",
        "\n",
        "print(ibes.columns)\n",
        "print(ibes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "THuAfWDIfyUq"
      },
      "outputs": [],
      "source": [
        "#8\n",
        "\n",
        "#merdge using left join\n",
        "dataonrdq= maindf.merge(ibes, how= 'left', on= ['tic', 'year', 'month'])\n",
        "\n",
        "print(maindf.columns)\n",
        "print(maindf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jEdITGijgnqI"
      },
      "outputs": [],
      "source": [
        "#9a\n",
        "#add sue deciles from pervious quarter\n",
        "\n",
        "dataonrdq= maindf.dropna()\n",
        "suedeciles= dataonrdq.drop_duplicates()\n",
        "suedeciles= suedeciles('year','qtr')\n",
        "\n",
        "\n",
        "# #new df with quantiles\n",
        "# for i in range(1,10):\n",
        "#   #c??\n",
        "#   currentdecile= dataonrdq.groupby(['year', 'qtr'])['sue'].quantile(i/10)\n",
        "#   #creation of empty variable\n",
        "#   suedeciles['previous_qtr_decile'+ str(i)]== \"\"\n",
        "#   for j in suedeciles.index:\n",
        "#     suedeciles['previous_qtr_decile'+ str(i)][j] = currentdecile[suedeciles['year'][j], suedeciles['qtr'][j]]\n",
        "#   #shift(1) is one later period\n",
        "#   suedeciles['previous_qtr_decile'+ str(i)]= suedeciles['previous_qtr_decile'+ str(i)].shift(1)\n",
        "#   suedeciles['previous_qtr_decile'+ str(i)]= pd.to_numeric(suedeciles['previous_qtr_decile'+ str(i)], errors= 'coerce')\n",
        "\n",
        "\n",
        "\n",
        "#optimized, vectorized code\n",
        "# Calculate quantiles for each quarter\n",
        "quantiles = dataonrdq.groupby(['year', 'qtr'])['sue'].quantile([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "\n",
        "# Create a DataFrame to hold the results\n",
        "suedeciles = pd.DataFrame()\n",
        "\n",
        "# Loop through deciles and create columns\n",
        "for i in range(1, 10):\n",
        "    col_name = 'previous_qtr_decile' + str(i)\n",
        "\n",
        "    # Calculate shifted deciles\n",
        "    suedeciles[col_name] = quantiles.groupby(['year', 'qtr']).shift(1)[i/10]\n",
        "\n",
        "# Convert columns to numeric\n",
        "suedeciles = suedeciles.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(suedeciles.columns)\n",
        "print(suedeciles)\n",
        "\n",
        "  #currentdecile= currentdecile.rename(columns= {'sue': 'sue_decile_' + str(i)})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3vi1r_8MQl9Q"
      },
      "outputs": [],
      "source": [
        "# select specific suedeciles columns\n",
        "\n",
        "dataonrdq= dataonrdq.merge(suedeciles, how= 'left', on= ['year', 'qtr'])\n",
        "print(dataonrdq.columns)\n",
        "print(dataonrdq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S7QANedMQ23K"
      },
      "outputs": [],
      "source": [
        "dataonrdq.drop('index', inplace=True, axis=1)\n",
        "dataonrdq= dataonrdq.dropna()\n",
        "\n",
        "#drop 2nd quarter of overall data (2019Q2 bc sample size too small)\n",
        "#is | an and statement?\n",
        "dataonrdq= dataonrdq[(dataonrdq['year'] !=2019| dataonrdq['qtr'] != 2)]\n",
        "\n",
        "#does below line create an index which we later drop?\n",
        "dataonrdq= dataonrdq.reset_index()\n",
        "dataonrdq.drop('index', inplace=True, axis=1)\n",
        "\n",
        "\n",
        "print(dataonrdq.columns)\n",
        "print(dataonrdq)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-5f8a9xiSMjW"
      },
      "outputs": [],
      "source": [
        "#9b\n",
        "#add sue decile to every row\n",
        "\n",
        "# Calculate the SUE decile boundaries\n",
        "num_deciles = 10\n",
        "dataonrdq['SUE_decile'] = pd.qcut(dataonrdq['SUE'], num_deciles, labels=False)\n",
        "\n",
        "def map_decile_label(decile):\n",
        "    return f'Decile {decile + 1}'\n",
        "\n",
        "dataonrdq['sue_decile'] = dataonrdq['SUE_decile'].apply(map_decile_label)\n",
        "\n",
        "print(dataonrdq.columns)\n",
        "print(dataonrdq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CXRoMY0MVV8B"
      },
      "outputs": [],
      "source": [
        "#9c\n",
        "#merge sue decile into main df\n",
        "\n",
        "maindf= maindf.merge(dataonrdq, how= 'left', on= ['tic', 'year', 'qtr'])\n",
        "\n",
        "maindf.drop('index', inplace=True, axis=1)\n",
        "maindf['date'] = pd.to_datetime(maindf['date'], errors='coerce')\n",
        "maindf['datadate']= pd.to_datetime(maindf['datadate'], errors='coerce')\n",
        "maindf['tic']= maindf['tic'].astype(str)\n",
        "\n",
        "\n",
        "print(maindf.columns)\n",
        "print(maindf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ll5wFYoyuVRO"
      },
      "outputs": [],
      "source": [
        "maindf= maindf.groupby(['tic', 'date'], as_index= False)\n",
        "maindf= maindf.first()\n",
        "\n",
        "print(maindf.columns)\n",
        "print(maindf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Cxcc2pb-yGFd"
      },
      "outputs": [],
      "source": [
        "#CLEAN ONLY HAVE NESSESARY COLUMNS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VUjP8C_9DYnK"
      },
      "outputs": [],
      "source": [
        "og_og_maindf_checkpoint= maindf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6qB6tHH7wKJO"
      },
      "outputs": [],
      "source": [
        "#checkpoint\n",
        "originalmain= maindf\n",
        "maindf= originalmain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a9MhV4cjxxvR"
      },
      "outputs": [],
      "source": [
        "#10\n",
        "#calculate CAR\n",
        "\n",
        "ticofRdq= maindf.dropna()\n",
        "ticofRdq=ticofRdq[['tic','sue_decile','size_decile']]\n",
        "\n",
        "print(ticofRdq.columns)\n",
        "print(ticofRdq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YgUo9szrwKRF"
      },
      "outputs": [],
      "source": [
        "abnret= maindf.reset_index()\n",
        "abnret= abnret[['original_index', 'tic', 'date', 'datadate', 'year','qtr', 'ret','rdq', 'size_decile','avg_ret', 'abn_ret','sue', 'sue_decile']]\n",
        "\n",
        "print(abnret.columns)\n",
        "print(abnret)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y3B_QSjWzyr4"
      },
      "outputs": [],
      "source": [
        "abnret= abnret.groupby(['tic', 'original_index'], as_index= False)['abn_ret'].first()\n",
        "abnret['new_index']= abnret['tic'].astype(str)+'_'+abnret['original_index'].astype(str)\n",
        "abnret= abnret.set_index('new_index')\n",
        "\n",
        "print(abnret.columns)\n",
        "print(abnret)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "29ODfLme0XP3"
      },
      "outputs": [],
      "source": [
        "abnRet= abnret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTDpBRD0g_fq"
      },
      "source": [
        "GRAPHS FOR ALL FIRMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_1mB85on9y2A"
      },
      "outputs": [],
      "source": [
        "### ALL FIRMS: Calculate Cumulative Abnormal Returns for Every RDQ ###\n",
        "\n",
        "# carArrayBeforeAll = []\n",
        "# carArrayAfterAll= []\n",
        "\n",
        "# for i in range(11):\n",
        "#   carArrayAfterAll.append([])\n",
        "#   carArrayBeforeAll.append([])\n",
        "\n",
        "# #Calculate CAR and store them in corresponding SUE Deciles\n",
        "# n = 60 #set to number of days before/after RDQ to be analyzed\n",
        "# for rdqDate in TicOfRDQ.index:\n",
        "# #Generate indices for abnormal return dataframe.\n",
        "#   nDaysBeforeIndex= str(TicOfRDQ['tic'][rdqDate]) + \"_\" + str(rdqDate - n)\n",
        "#   rdqDateIndex = str(TicOfRDQ['tic'][rdqDate])+\"/\"+ str(rdqDate)\n",
        "#   nDaysAfterIndex = str(TicOfRDQ['tic'][rdqDate]) + \"_\" + str(rdqDate + n)\n",
        "# #check if n days before and after RDQ abnormal return data exist\n",
        "#   if (nDaysBeforeIndex in abnRet.index) and (nDaysAfterIndex in abnRet.index):\n",
        "# #Add n days before CAR\n",
        "#   beforeDF = pd.DataFrame(abnRet.loc[nDaysBeforeIndex: rdqDateIndex]).reset_index()\n",
        "#   #calculate CAR (sum of all abn_ret first abn_ret)\n",
        "#   beforeDF['car'] = beforeDF['abn_ret'].cumsum() - beforeDF ['abn_ret'][0]\n",
        "#   carArrayBeforeAll[TicOfRDQ['sue_decile'][rdqDate].astype(int)].append(beforeDF['car'])\n",
        "#   #Add n days after CAR\n",
        "#   afterDF= pd.DataFrame(abnRet.loc[rdqDate Index: nDaysAfterIndex]).reset_index()\n",
        "#   #calculate CAR (sum of all abn_ret first abn_ret)\n",
        "#   afterDF['car'] = afterDF['abn_ret'].cumsum() - afterDF ['abn_ret'][0]\n",
        "#   carArrayAfterAll [TicOfRDQ['sue_decile'][rdqDate].astype (int)].append(afterDF['car'])\n",
        "\n",
        "\n",
        "\n",
        "# Initialize CAR arrays\n",
        "carArrayBeforeAll = [[] for _ in range(11)]\n",
        "carArrayAfterAll = [[] for _ in range(11)]\n",
        "\n",
        "# Calculate CAR and store them in corresponding SUE Deciles\n",
        "n = 60  # set to number of days before/after RDQ to be analyzed\n",
        "\n",
        "# Convert index to datetime if not already, MIGHT BE WRONG\n",
        "TicOfRDQ.index = pd.to_datetime(TicOfRDQ.index)\n",
        "\n",
        "for rdqDate in TicOfRDQ.index:\n",
        "    tic = TicOfRDQ.at[rdqDate, 'tic']\n",
        "    sue_decile = TicOfRDQ.at[rdqDate, 'sue_decile']\n",
        "\n",
        "    nDaysBeforeIndex = tic + \"_\" + str(rdqDate - pd.Timedelta(days=n))\n",
        "    rdqDateIndex = tic + \"/\" + str(rdqDate)\n",
        "    nDaysAfterIndex = tic + \"_\" + str(rdqDate + pd.Timedelta(days=n))\n",
        "\n",
        "    if nDaysBeforeIndex in abnRet.index and nDaysAfterIndex in abnRet.index:\n",
        "        beforeDF = abnRet.loc[nDaysBeforeIndex:rdqDateIndex].reset_index()\n",
        "        beforeDF['car'] = np.cumsum(beforeDF['abn_ret']) - beforeDF['abn_ret'][0]\n",
        "        carArrayBeforeAll[sue_decile].append(beforeDF['car'])\n",
        "\n",
        "        afterDF = abnRet.loc[rdqDateIndex:nDaysAfterIndex].reset_index()\n",
        "        afterDF['car'] = np.cumsum(afterDF['abn_ret']) - afterDF['abn_ret'][0]\n",
        "        carArrayAfterAll[sue_decile].append(afterDF['car'])\n",
        "\n",
        "# Convert carArrayBeforeAll and carArrayAfterAll to numpy arrays for efficient storage/manipulation\n",
        "carArrayBeforeAll = [np.array(lst) for lst in carArrayBeforeAll]\n",
        "carArrayAfterAll = [np.array(lst) for lst in carArrayAfterAll]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2kj6P5Ps92Mm"
      },
      "outputs": [],
      "source": [
        "# #11a\n",
        "# #ALL FIRMS: Generate New CAR Arrays for Each Decile and Each Day ###\n",
        "\n",
        "# #Create new array to store CAR data on each day before RDDQ\n",
        "\n",
        "# carAllByDaysBefore= [] #n days before RDQ\n",
        "# #Set up empty array, 11 by 61\n",
        "# for i in range(11):\n",
        "#   carAllByDaysBefore.append([])\n",
        "#   for i in range(61):\n",
        "#    carAllByDaysBefore[i].append([])\n",
        "\n",
        "# #Add CAR data\n",
        "# #i is for each decile\n",
        "# #k is days before rdq\n",
        "# #for each combo of i and k, a car value is added\n",
        "# for i in range(len(carArrayBeforeAll)):\n",
        "#   for j in range(len(carArrayBeforeAll[i])):\n",
        "#     for k in range(len(carAllByDaysBefore[i])):\n",
        "#       carAllByDaysBefore[i][k].append(carArrayBeforeAll[i][j][k])\n",
        "\n",
        "\n",
        "# #Create new array to store CAR data on each day after RDQ\n",
        "# carAllByDaysAfter= [] #n days after RDQ\n",
        "# #Set up empty array for i in range(11):\n",
        "# carAllByDaysAfter.append([])\n",
        "# for i in range(61):\n",
        "#   carAllByDaysAfter[i].append([])\n",
        "\n",
        "# #Add CAR data\n",
        "\n",
        "# for i in range(len(carArrayAfterAll)):\n",
        "#   for i in range(len(carArrayAfterAll[1])):\n",
        "#     for k in range(len(carAllByDaysAfter[1])):\n",
        "#       carAllByDaysAfter[1][k].append(carArrayAfterAll[i][j][k])\n",
        "\n",
        "\n",
        "# Initialize CAR arrays using NumPy arrays\n",
        "num_deciles = 11\n",
        "num_days = 61\n",
        "\n",
        "carAllByDaysBefore = np.empty((num_deciles, num_days), dtype=object)\n",
        "carAllByDaysAfter = np.empty((num_deciles, num_days), dtype=object)\n",
        "\n",
        "# Populate CAR data for days before RDDQ\n",
        "for i in range(len(carArrayBeforeAll)):\n",
        "    for j in range(len(carArrayBeforeAll[i])):\n",
        "        carAllByDaysBefore[i, j] = carArrayBeforeAll[i][j]\n",
        "\n",
        "# Populate CAR data for days after RDDQ\n",
        "for i in range(len(carArrayAfterAll)):\n",
        "    for j in range(len(carArrayAfterAll[i])):\n",
        "        carAllByDaysAfter[1, j] = carArrayAfterAll[i][j]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_nbexv1-95CV"
      },
      "outputs": [],
      "source": [
        "#11b\n",
        "\n",
        "#ALL FIRMS: Generate Dataframe with Average CAR for Each Day before RDQ ###\n",
        "\n",
        "#new dataframe to store data\n",
        "\n",
        "avgCARAllBefore = pd.DataFrame()\n",
        "\n",
        "# for i in range(1, 11):\n",
        "#     #take 100 average of that day to get average % CAR\n",
        "#   avgCARAllBefore['decile_'+ str(i)]= 100 * pd.DataFrame(carAllByDaysBefore[i]).mean(axis=1)\n",
        "# # Calculate average CAR for each decile and each day before RDQ\n",
        "for i in range(1, 11):\n",
        "    # Calculate average CAR and store in the DataFrame\n",
        "    avgCARAllBefore['decile_' + str(i)] = 100 * np.mean(carAllByDaysBefore[i], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#Add column to store days relative to RDQ\n",
        "avgCARAllBefore= avgCARAllBefore.reset_index()\n",
        "avgCARAllBefore= avgCARAllBefore.rename(columns={'index': 'days relative_to_rdq'})\n",
        "\n",
        "#make days relative to RDQ in range [-60, 0] since data is before RDQ\n",
        "avgCARAllBefore['days relative_to_rdq'] = pd.to_numeric(avgCARAllBefore['days_relative_to_rdq'], errors = 'coerce')\n",
        "#subtracts 60 from each date, shifts timeframe to 60 days before (-60, 0)\n",
        "avgCARAllBefore['days_relative_to_rdq'] -= 60\n",
        "\n",
        "\n",
        "print(avgCARAllBefore.columns)\n",
        "print(avgCARAllBefore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "egnkZQbw97Qb"
      },
      "outputs": [],
      "source": [
        "#11c\n",
        "\n",
        "# ALL Firms Generate and Save Figure 2 graph Before RDQ\n",
        "\n",
        "#Plot graph in Python\n",
        "allFirmsBeforeRDQ = avgCARAllBefore.plot(x= 'days relative to rdq', y= ['decile_1, decile_2, decile_3, decile_4, decile_5, decile_6, decile_7, decile_8, decile_9, decile_10'], kind= \"line\", figsize=[20,15], title= \"Figure 2a: CAR before RDQ for All Firms\")\n",
        "\n",
        "allFirmsBeforeRDQ.set_xlabel(\"Event Time In Trading Days Relative to Earnings Announcement Day\")\n",
        "allFirmsBeforeRDQ.set_ylabel(\"Cumulative Abnormal Return (%)\")\n",
        "\n",
        "#save graph in Google Drive folder\n",
        "fig= allFirmsBeforeRDQ.get_figure()\n",
        "fig.savefig(\"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD\"+ \"/allFirmsBeforeRDQ.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OV_An5YX-BmH"
      },
      "outputs": [],
      "source": [
        "#12\n",
        "#Repeat Steps 11b & 11c for all firms after RDQ\n",
        "\n",
        "\n",
        "#ALL FIRMS: Generate Dataframe with Average CAR for Each Day before RDQ ###\n",
        "\n",
        "#new dataframe to store data\n",
        "avgCARAllAfter = pd.DataFrame()\n",
        "# # Calculate average CAR for each decile and each day before RDQ\n",
        "for i in range(1, 11):\n",
        "    # Calculate average CAR and store in the DataFrame\n",
        "    avgCARAllAfter['decile_' + str(i)] = 100 * np.mean(carAllByDaysAfter[i], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#Add column to store days relative to RDQ\n",
        "avgCARAllAfter= avgCARAllAfter.reset_index()\n",
        "avgCARAllAfter= avgCARAllAfter.rename(columns={'index': 'days relative_to_rdq'})\n",
        "\n",
        "#make days relative to RDQ in range [-60, 0] since data is before RDQ\n",
        "avgCARAllAfter['days relative_to_rdq'] = pd.to_numeric(avgCARAllAfter['days_relative_to_rdq'], errors = 'coerce')\n",
        "#subtracts 60 from each date, shifts timeframe to 60 days before (-60, 0)\n",
        "avgCARAllAfter['days_relative_to_rdq'] -= 60\n",
        "\n",
        "\n",
        "print(avgCARAllAfter.columns)\n",
        "print(avgCARAllAfter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-icmGpnrWsFU"
      },
      "outputs": [],
      "source": [
        "# ALL Firms Generate and Save Figure 2 graph Before RDQ\n",
        "\n",
        "#Plot graph in Python\n",
        "allFirmsAfterRDQ = avgCARAllAfter.plot(x= 'days relative to rdq', y= ['decile_1, decile_2, decile_3, decile_4, decile_5, decile_6, decile_7, decile_8, decile_9, decile_10'], kind= \"line\", figsize=[20,15], title= \"Figure 2a: CAR before RDQ for All Firms\")\n",
        "\n",
        "allFirmsAfterRDQ.set_xlabel(\"Event Time In Trading Days Relative to Earnings Announcement Day\")\n",
        "allFirmsAfterRDQ.set_ylabel(\"Cumulative Abnormal Return (%)\")\n",
        "\n",
        "#save graph in Google Drive folder\n",
        "fig= allFirmsAfterRDQ.get_figure()\n",
        "fig.savefig(\"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD\"+ \"/allFirmsAfterRDQ.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzSvuoWug3xx"
      },
      "source": [
        "GRAPHS FOR BIG FIRMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iw5Q26FWZkpX"
      },
      "outputs": [],
      "source": [
        "#13\n",
        "#steps 10-12 for big firms\n",
        "\n",
        "#checkpoint\n",
        "maindf= originalmain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UfYdMi6R-D45"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Only keep big firms (top 3 size deciles)\n",
        "\n",
        "maindf = maindf[maindf['size_decile'] >= 8]\n",
        "maindf = maindf.reset_index()\n",
        "maindf.drop('index', inplace=True, axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aljajDPZawZP"
      },
      "outputs": [],
      "source": [
        "\n",
        "#df might not exist, use dataonrdq\n",
        "\n",
        "ticofRdqBig= maindf.dropna()\n",
        "ticofRdqBig=ticofRdqBig[['tic','sue_decile','size_decile']]\n",
        "\n",
        "print(ticofRdqBig.columns)\n",
        "print(ticofRdqBig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DHyPGpwvd5GO"
      },
      "outputs": [],
      "source": [
        "abnretBig= maindf.reset_index()\n",
        "abnretBig= abnretBig[['original_index', 'tic', 'date', 'datadate', 'year','qtr', 'ret','rdq', 'size_decile','avg_ret', 'abn_ret','sue', 'sue_decile']]\n",
        "\n",
        "print(abnretBig.columns)\n",
        "print(abnretBig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e9-kxpvvd8Pi"
      },
      "outputs": [],
      "source": [
        "abnretBig= abnretBig.groupby(['tic', 'original_index'], as_index= False)['abn_ret'].first()\n",
        "abnretBig['new_index']= abnretBig['tic'].astype(str)+'_'+abnretBig['original_index'].astype(str)\n",
        "abnretBig= abnretBig.set_index('new_index')\n",
        "\n",
        "print(abnretBig.columns)\n",
        "print(abnretBig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lOTIwZrUeSdl"
      },
      "outputs": [],
      "source": [
        "#initialize CAR arrays\n",
        "carArrayBeforeBig = [[] for _ in range(11)]\n",
        "carArrayAfterBig = [[] for _ in range(11)]\n",
        "\n",
        "# Calculate CAR and store them in corresponding SUE Deciles\n",
        "n = 60  # set to number of days before/after RDQ to be analyzed\n",
        "\n",
        "# Convert index to datetime if not already, MIGHT BE WRONG\n",
        "ticofRdqBig.index = pd.to_datetime(ticofRdqBig.index)\n",
        "\n",
        "for rdqDate in ticofRdqBig.index:\n",
        "    tic = ticofRdqBig.at[rdqDate, 'tic']\n",
        "    sue_decile = ticofRdqBig.at[rdqDate, 'sue_decile']\n",
        "\n",
        "    nDaysBeforeIndex = tic + \"_\" + str(rdqDate - pd.Timedelta(days=n))\n",
        "    rdqDateIndex = tic + \"/\" + str(rdqDate)\n",
        "    nDaysAfterIndex = tic + \"_\" + str(rdqDate + pd.Timedelta(days=n))\n",
        "\n",
        "    if nDaysBeforeIndex in abnRet.index and nDaysAfterIndex in abnRet.index:\n",
        "        beforeDF = abnRet.loc[nDaysBeforeIndex:rdqDateIndex].reset_index()\n",
        "        beforeDF['car'] = np.cumsum(beforeDF['abn_ret']) - beforeDF['abn_ret'][0]\n",
        "        carArrayBeforeAll[sue_decile].append(beforeDF['car'])\n",
        "\n",
        "        afterDF = abnRet.loc[rdqDateIndex:nDaysAfterIndex].reset_index()\n",
        "        afterDF['car'] = np.cumsum(afterDF['abn_ret']) - afterDF['abn_ret'][0]\n",
        "        carArrayAfterAll[sue_decile].append(afterDF['car'])\n",
        "\n",
        "# Convert carArrayBeforeAll and carArrayAfterAll to numpy arrays for efficient storage/manipulation\n",
        "carArrayBeforeBig = [np.array(lst) for lst in carArrayBeforeBig]\n",
        "carArrayAfterBig = [np.array(lst) for lst in carArrayAfterBig]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DgQMh2gHfFBq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize CAR arrays using NumPy arrays\n",
        "num_deciles = 11\n",
        "num_days = 61\n",
        "\n",
        "carbigByDaysBefore = np.empty((num_deciles, num_days), dtype=object)\n",
        "carbigByDaysAfter = np.empty((num_deciles, num_days), dtype=object)\n",
        "\n",
        "# Populate CAR data for days before RDDQ\n",
        "for i in range(len(carArrayBeforeBig)):\n",
        "    for j in range(len(carArrayBeforeBig[i])):\n",
        "        carbigByDaysBefore[i, j] = carArrayBeforeBig[i][j]\n",
        "\n",
        "# Populate CAR data for days after RDDQ\n",
        "for i in range(len(carArrayAfterBig)):\n",
        "    for j in range(len(carArrayAfterBig[i])):\n",
        "        carbigByDaysAfter[1, j] = carArrayAfterBig[i][j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Wb1GdycufyMg"
      },
      "outputs": [],
      "source": [
        "#11b\n",
        "\n",
        "#ALL FIRMS: Generate Dataframe with Average CAR for Each Day before RDQ ###\n",
        "\n",
        "#new dataframe to store data\n",
        "\n",
        "avgCARBIGBefore = pd.DataFrame()\n",
        "\n",
        "# # Calculate average CAR for each decile and each day before RDQ\n",
        "for i in range(1, 11):\n",
        "    # Calculate average CAR and store in the DataFrame\n",
        "    avgCARBIGBefore['decile_' + str(i)] = 100 * np.mean(carbigByDaysBefore[i], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#Add column to store days relative to RDQ\n",
        "avgCARBIGBefore= avgCARBIGBefore.reset_index()\n",
        "avgCARBIGBefore= avgCARBIGBefore.rename(columns={'index': 'days relative_to_rdq'})\n",
        "\n",
        "#make days relative to RDQ in range [-60, 0] since data is before RDQ\n",
        "avgCARBIGBefore['days relative_to_rdq'] = pd.to_numeric(avgCARBIGBefore['days_relative_to_rdq'], errors = 'coerce')\n",
        "#subtracts 60 from each date, shifts timeframe to 60 days before (-60, 0)\n",
        "avgCARBIGBefore['days_relative_to_rdq'] -= 60\n",
        "\n",
        "\n",
        "print(avgCARBIGBefore.columns)\n",
        "print(avgCARBIGBefore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WpfZkFi-gFQM"
      },
      "outputs": [],
      "source": [
        "#11c\n",
        "\n",
        "# big Firms Generate and Save Figure 2 graph Before RDQ\n",
        "\n",
        "#Plot graph in Python\n",
        "bigFirmsBeforeRDQ = avgCARBIGBefore.plot(x= 'days relative to rdq', y= ['decile_1, decile_2, decile_3, decile_4, decile_5, decile_6, decile_7, decile_8, decile_9, decile_10'], kind= \"line\", figsize=[20,15], title= \"Figure 2a: CAR before RDQ for Big Firms\")\n",
        "\n",
        "bigFirmsBeforeRDQ.set_xlabel(\"Event Time In Trading Days Relative to Earnings Announcement Day\")\n",
        "bigFirmsBeforeRDQ.set_ylabel(\"Cumulative Abnormal Return (%)\")\n",
        "\n",
        "#save graph in Google Drive folder\n",
        "fig= bigFirmsBeforeRDQ.get_figure()\n",
        "fig.savefig(\"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD\"+ \"/bigFirmsBeforeRDQ.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhWFyFuTgyCd"
      },
      "source": [
        "GRAPHS FOR SMALL FIRMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DVXppltmhELL"
      },
      "outputs": [],
      "source": [
        "maindf= originalmain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bu3fbk3AhEVT"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Only keep big firms (top 3 size deciles)\n",
        "\n",
        "mainDF = mainDF[mainDF['size_decile'] <= 4]\n",
        "mainDF = mainDF.reset_index()\n",
        "mainDF.drop('index', inplace=True, axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fg3g1afKhvQy"
      },
      "outputs": [],
      "source": [
        "\n",
        "ticofRdqSmall= maindf.dropna()\n",
        "ticofRdqSmall=ticofRdqSmall[['tic','sue_decile','size_decile']]\n",
        "\n",
        "\n",
        "print(ticofRdqSmall.columns)\n",
        "print(ticofRdqSmall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PlV8gGhdh0oe"
      },
      "outputs": [],
      "source": [
        "abnretSmall= maindf.reset_index()\n",
        "abnretSmall= abnretSmall[['original_index', 'tic', 'date', 'datadate', 'year','qtr', 'ret','rdq', 'size_decile','avg_ret', 'abn_ret','sue', 'sue_decile']]\n",
        "\n",
        "print(abnretSmall.columns)\n",
        "print(abnretSmall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ImBqtoa7h7cz"
      },
      "outputs": [],
      "source": [
        "abnretSmall= abnretSmall.groupby(['tic', 'original_index'], as_index= False)['abn_ret'].first()\n",
        "abnretSmall['new_index']= abnretSmall['tic'].astype(str)+'_'+abnretSmall['original_index'].astype(str)\n",
        "abnretSmall= abnretSmall.set_index('new_index')\n",
        "\n",
        "print(abnretSmall.columns)\n",
        "print(abnretSmall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CN8KIDleiDy-"
      },
      "outputs": [],
      "source": [
        "#initialize CAR arrays\n",
        "carArrayBeforeSmall = [[] for _ in range(11)]\n",
        "carArrayAfterSmall = [[] for _ in range(11)]\n",
        "\n",
        "# Calculate CAR and store them in corresponding SUE Deciles\n",
        "n = 60  # set to number of days before/after RDQ to be analyzed\n",
        "\n",
        "# Convert index to datetime if not already, MIGHT BE WRONG\n",
        "ticofRdqSmall.index = pd.to_datetime(ticofRdqSmall.index)\n",
        "\n",
        "for rdqDate in ticofRdqSmall.index:\n",
        "    tic = ticofRdqSmall.at[rdqDate, 'tic']\n",
        "    sue_decile = ticofRdqSmall.at[rdqDate, 'sue_decile']\n",
        "\n",
        "    nDaysBeforeIndex = tic + \"_\" + str(rdqDate - pd.Timedelta(days=n))\n",
        "    rdqDateIndex = tic + \"/\" + str(rdqDate)\n",
        "    nDaysAfterIndex = tic + \"_\" + str(rdqDate + pd.Timedelta(days=n))\n",
        "\n",
        "    if nDaysBeforeIndex in abnRet.index and nDaysAfterIndex in abnRet.index:\n",
        "        beforeDF = abnRet.loc[nDaysBeforeIndex:rdqDateIndex].reset_index()\n",
        "        beforeDF['car'] = np.cumsum(beforeDF['abn_ret']) - beforeDF['abn_ret'][0]\n",
        "        carArrayBeforeSmall[sue_decile].append(beforeDF['car'])\n",
        "\n",
        "        afterDF = abnRet.loc[rdqDateIndex:nDaysAfterIndex].reset_index()\n",
        "        afterDF['car'] = np.cumsum(afterDF['abn_ret']) - afterDF['abn_ret'][0]\n",
        "        carArrayAfterSmall[sue_decile].append(afterDF['car'])\n",
        "\n",
        "# Convert carArrayBeforeAll and carArrayAfterAll to numpy arrays for efficient storage/manipulation\n",
        "carArrayBeforeSmall = [np.array(lst) for lst in carArrayBeforeSmall]\n",
        "carArrayAfterSmall = [np.array(lst) for lst in carArrayAfterSmall]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q6eXgPHykdLC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize CAR arrays using NumPy arrays\n",
        "num_deciles = 11\n",
        "num_days = 61\n",
        "\n",
        "carsmallByDaysBefore = np.empty((num_deciles, num_days), dtype=object)\n",
        "carsmallByDaysAfter = np.empty((num_deciles, num_days), dtype=object)\n",
        "\n",
        "# Populate CAR data for days before RDDQ\n",
        "for i in range(len(carArrayBeforeSmall)):\n",
        "    for j in range(len(carArrayBeforeSmall[i])):\n",
        "        carsmallByDaysBefore[i, j] = carArrayBeforeSmall[i][j]\n",
        "\n",
        "# Populate CAR data for days after RDDQ\n",
        "for i in range(len(carArrayAfterSmall)):\n",
        "    for j in range(len(carArrayAfterSmall[i])):\n",
        "        carsmallByDaysAfter[1, j] = carArrayAfterSmall[i][j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "C2Mm3YxakxyI"
      },
      "outputs": [],
      "source": [
        "#11b\n",
        "\n",
        "#ALL FIRMS: Generate Dataframe with Average CAR for Each Day before RDQ ###\n",
        "\n",
        "#new dataframe to store data\n",
        "\n",
        "avgCARSMALLBefore = pd.DataFrame()\n",
        "\n",
        "# # Calculate average CAR for each decile and each day before RDQ\n",
        "for i in range(1, 11):\n",
        "    # Calculate average CAR and store in the DataFrame\n",
        "    avgCARSMALLBefore['decile_' + str(i)] = 100 * np.mean(carsmallByDaysBefore[i], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#Add column to store days relative to RDQ\n",
        "avgCARSMALLBefore= avgCARSMALLBefore.reset_index()\n",
        "avgCARSMALLBefore= avgCARSMALLBefore.rename(columns={'index': 'days relative_to_rdq'})\n",
        "\n",
        "#make days relative to RDQ in range [-60, 0] since data is before RDQ\n",
        "avgCARSMALLBefore['days relative_to_rdq'] = pd.to_numeric(avgCARSMALLBefore['days_relative_to_rdq'], errors = 'coerce')\n",
        "#subtracts 60 from each date, shifts timeframe to 60 days before (-60, 0)\n",
        "avgCARSMALLBefore['days_relative_to_rdq'] -= 60\n",
        "\n",
        "\n",
        "print(avgCARSMALLBefore.columns)\n",
        "print(avgCARSMALLBefore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R8RdEjbKlGr-"
      },
      "outputs": [],
      "source": [
        "#11c\n",
        "\n",
        "# small Firms Generate and Save Figure 2 graph Before RDQ\n",
        "\n",
        "#Plot graph in Python\n",
        "smallFirmsBeforeRDQ = avgCARSMALLBefore.plot(x= 'days relative to rdq', y= ['decile_1, decile_2, decile_3, decile_4, decile_5, decile_6, decile_7, decile_8, decile_9, decile_10'], kind= \"line\", figsize=[20,15], title= \"Figure 2a: CAR before RDQ for Big Firms\")\n",
        "\n",
        "smallFirmsBeforeRDQ.set_xlabel(\"Event Time In Trading Days Relative to Earnings Announcement Day\")\n",
        "smallFirmsBeforeRDQ.set_ylabel(\"Cumulative Abnormal Return (%)\")\n",
        "\n",
        "#save graph in Google Drive folder\n",
        "fig= smallFirmsBeforeRDQ.get_figure()\n",
        "fig.savefig(\"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD\"+ \"/smallFirmsBeforeRDQ.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPOceY1WzIKj"
      },
      "source": [
        "medium firms before RDQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "06diUFVk3QTF"
      },
      "outputs": [],
      "source": [
        "maindf= originalmain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wcfVYMos3SUI"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Only keep big firms (top 3 size deciles)\n",
        "\n",
        "mainDF = mainDF[mainDF['size_decile'] >= 5]\n",
        "mainDF = mainDF[mainDF['size_decile'] <= 7]\n",
        "mainDF = mainDF.reset_index()\n",
        "mainDF.drop('index', inplace=True, axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f6-ctKPh3mbS"
      },
      "outputs": [],
      "source": [
        "\n",
        "ticofRdqMed= maindf.dropna()\n",
        "ticofRdqMed=ticofRdqSmall[['tic','sue_decile','size_decile']]\n",
        "\n",
        "\n",
        "print(ticofRdqMed.columns)\n",
        "print(ticofRdqMed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9k-i-goX3ooT"
      },
      "outputs": [],
      "source": [
        "abnretMed= maindf.reset_index()\n",
        "abnretMed= abnretMed[['original_index', 'tic', 'date', 'datadate', 'year','qtr', 'ret','rdq', 'size_decile','avg_ret', 'abn_ret','sue', 'sue_decile']]\n",
        "\n",
        "print(abnretMed.columns)\n",
        "print(abnretMed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zDZighu43rb8"
      },
      "outputs": [],
      "source": [
        "abnretMed= abnretMed.groupby(['tic', 'original_index'], as_index= False)['abn_ret'].first()\n",
        "abnretMed['new_index']= abnretMed['tic'].astype(str)+'_'+abnretMed['original_index'].astype(str)\n",
        "abnretMed= abnretMed.set_index('new_index')\n",
        "\n",
        "print(abnretSmall.columns)\n",
        "print(abnretSmall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c4z2vr1W3teJ"
      },
      "outputs": [],
      "source": [
        "#initialize CAR arrays\n",
        "carArrayBeforeMed = [[] for _ in range(11)]\n",
        "carArrayAfterMed = [[] for _ in range(11)]\n",
        "\n",
        "# Calculate CAR and store them in corresponding SUE Deciles\n",
        "n = 60  # set to number of days before/after RDQ to be analyzed\n",
        "\n",
        "# Convert index to datetime if not already, MIGHT BE WRONG\n",
        "ticofRdqMed.index = pd.to_datetime(ticofRdqMed.index)\n",
        "\n",
        "for rdqDate in ticofRdqMed.index:\n",
        "    tic = ticofRdqMed.at[rdqDate, 'tic']\n",
        "    sue_decile = ticofRdqMed.at[rdqDate, 'sue_decile']\n",
        "\n",
        "    nDaysBeforeIndex = tic + \"_\" + str(rdqDate - pd.Timedelta(days=n))\n",
        "    rdqDateIndex = tic + \"/\" + str(rdqDate)\n",
        "    nDaysAfterIndex = tic + \"_\" + str(rdqDate + pd.Timedelta(days=n))\n",
        "\n",
        "    if nDaysBeforeIndex in abnRet.index and nDaysAfterIndex in abnRet.index:\n",
        "        beforeDF = abnRet.loc[nDaysBeforeIndex:rdqDateIndex].reset_index()\n",
        "        beforeDF['car'] = np.cumsum(beforeDF['abn_ret']) - beforeDF['abn_ret'][0]\n",
        "        carArrayBeforeMed[sue_decile].append(beforeDF['car'])\n",
        "\n",
        "        afterDF = abnRet.loc[rdqDateIndex:nDaysAfterIndex].reset_index()\n",
        "        afterDF['car'] = np.cumsum(afterDF['abn_ret']) - afterDF['abn_ret'][0]\n",
        "        carArrayAfterMed[sue_decile].append(afterDF['car'])\n",
        "\n",
        "# Convert carArrayBeforeAll and carArrayAfterAll to numpy arrays for efficient storage/manipulation\n",
        "carArrayBeforeMed = [np.array(lst) for lst in carArrayBeforeMed]\n",
        "carArrayAfterMed = [np.array(lst) for lst in carArrayAfterMed]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aUNQ9y8x4uxe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize CAR arrays using NumPy arrays\n",
        "num_deciles = 11\n",
        "num_days = 61\n",
        "\n",
        "carmedByDaysBefore = np.empty((num_deciles, num_days), dtype=object)\n",
        "carmedByDaysAfter = np.empty((num_deciles, num_days), dtype=object)\n",
        "\n",
        "# Populate CAR data for days before RDDQ\n",
        "for i in range(len(carArrayBeforeMed)):\n",
        "    for j in range(len(carArrayBeforeMed[i])):\n",
        "        carmedByDaysBefore[i, j] = carArrayBeforeMed[i][j]\n",
        "\n",
        "# Populate CAR data for days after RDDQ\n",
        "for i in range(len(carArrayAfterMed)):\n",
        "    for j in range(len(carArrayAfterMed[i])):\n",
        "        carmedByDaysAfter[1, j] = carArrayAfterMed[i][j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TYcOch7a48FO"
      },
      "outputs": [],
      "source": [
        "#11b\n",
        "\n",
        "#ALL FIRMS: Generate Dataframe with Average CAR for Each Day before RDQ ###\n",
        "\n",
        "#new dataframe to store data\n",
        "\n",
        "avgCARMEDBefore = pd.DataFrame()\n",
        "\n",
        "# # Calculate average CAR for each decile and each day before RDQ\n",
        "for i in range(1, 11):\n",
        "    # Calculate average CAR and store in the DataFrame\n",
        "    avgCARMEDBefore['decile_' + str(i)] = 100 * np.mean(carsmallByDaysBefore[i], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#Add column to store days relative to RDQ\n",
        "avgCARMEDBefore= avgCARMEDBefore.reset_index()\n",
        "avgCARMEDBefore= avgCARMEDBefore.rename(columns={'index': 'days relative_to_rdq'})\n",
        "\n",
        "#make days relative to RDQ in range [-60, 0] since data is before RDQ\n",
        "avgCARMEDBefore['days relative_to_rdq'] = pd.to_numeric(avgCARMEDBefore['days_relative_to_rdq'], errors = 'coerce')\n",
        "#subtracts 60 from each date, shifts timeframe to 60 days before (-60, 0)\n",
        "avgCARMEDBefore['days_relative_to_rdq'] -= 60\n",
        "\n",
        "\n",
        "print(avgCARMEDBefore.columns)\n",
        "print(avgCARMEDBefore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hRF-pFHB5RYy"
      },
      "outputs": [],
      "source": [
        "# #11c\n",
        "\n",
        "# # small Firms Generate and Save Figure 2 graph Before RDQ\n",
        "\n",
        "# #Plot graph in Python\n",
        "# smallFirmsBeforeRDQ = avgCARSMALLBefore.plot(x= 'days relative to rdq', y= ['decile_1, decile_2, decile_3, decile_4, decile_5, decile_6, decile_7, decile_8, decile_9, decile_10'], kind= \"line\", figsize=[20,15], title= \"Figure 2a: CAR before RDQ for Big Firms\")\n",
        "\n",
        "# smallFirmsBeforeRDQ.set_xlabel(\"Event Time In Trading Days Relative to Earnings Announcement Day\")\n",
        "# smallFirmsBeforeRDQ.set_ylabel(\"Cumulative Abnormal Return (%)\")\n",
        "\n",
        "# #save graph in Google Drive folder\n",
        "# fig= smallFirmsBeforeRDQ.get_figure()\n",
        "# fig.savefig(\"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD\"+ \"/smallFirmsBeforeRDQ.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMOQ77Lb5S6W"
      },
      "source": [
        "15-day CAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m0Z46xxN-uv7"
      },
      "outputs": [],
      "source": [
        "#16\n",
        "#Generate CAR Data for 15-Day Periods\n",
        "\n",
        "# Generate CAR Data for Every 60d Period Until Day 480 ###\n",
        "\n",
        "periodLength= 15\n",
        "\n",
        "periodStartsToAnalyze [-59, -44, -29, -14, 1, 16, 31, 46, 61]\n",
        "\n",
        "#Big Firms\n",
        "#fill new dataframe with empty arrays to get CAR\n",
        "\n",
        "#filter for only highest and lowest sue deciles\n",
        "TicOfRDQBigHilo= TicOfRDQBig[(TicOfRDQBig['sue_decile'] == 1) |(TicOfRDQBig['sue_decile']==10)]\n",
        "carDaysAfterRDQBig = pd.DataFrame(index= periodStartsToAnalyze, columns = [1, 10])\n",
        "\n",
        "for i in carDaysAfterRDQBig.index:\n",
        "  for j in carDaysAfterRDQBig.columns:\n",
        "    carDaysAfterRDQBig[j][i] = []\n",
        "\n",
        "#Fill dataframe with arrays of CAR on the last day of the period\n",
        "for m in carDaysAfterRDQBig.index:\n",
        "  for rdqDate in TicOfRDQBigHiLo.index:\n",
        "    #Generate indices for abnormal return dataframe\n",
        "    mDaysAfterRDQStartIndex = str(TicOfRDQBigHiLo['tic'][rdqDate]) + \"/\" + str(rdqDate + m)\n",
        "    mDaysAfterRDQEndIndex = str(TicOfRDQBigHiLo['tic'][rdqDate]) + \"/\" + str(rdqDate + m + periodLength - 1)\n",
        "    #check if indices exist\n",
        "    if (mDaysAfterRDQStartIndex in abnRetBig.index) and (mDaysAfterRDQEndIndex in abnRetBig.index):\n",
        "    periodDF= pd.DataFrame(abnRetBig.loc[mDaysAfterRDQStartIndex: mDaysAfterRDQEndIndex]).reset_index()\n",
        "    #calculate CAR (no need to subtract since first data is included)\n",
        "    periodDF['car'] = periodDF['abn_ret'].cumsum()\n",
        "    carDaysAfterRDQBig[TicOfRDQBigHiLo['sue_decile'][rdqDate]][m].append(periodDF['car'][periodLength - 1])\n",
        "\n",
        "#Take averages of each array to get average CAR on final day\n",
        "for i in carDaysAfterRDQBig.index:\n",
        "  for j in carDaysAfterRDQBig.columns:\n",
        "    #multiply by 100 to get percent value\n",
        "    carDaysAfterRDQBig[j]= np.average(carDaysAfterRDQBig[j][i]) *100\n",
        "\n",
        "\n",
        "print(carDaysAfterRDQBig.columns)\n",
        "print(carDaysAfterRDQBig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgMLLtUiEFDN"
      },
      "source": [
        "15 day car for med"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r8TWZOKhEEHI"
      },
      "outputs": [],
      "source": [
        "#16\n",
        "#Generate CAR Data for 15-Day Periods\n",
        "\n",
        "# Generate CAR Data for Every 60d Period Until Day 480 ###\n",
        "\n",
        "#medium Firms\n",
        "#fill new dataframe with empty arrays to get CAR\n",
        "\n",
        "#filter for only highest and lowest sue deciles\n",
        "TicOfRDQMedHilo= TicOfRDQMed[(TicOfRDQMed['sue_decile'] == 1) |(TicOfRDQMed['sue_decile']==10)]\n",
        "carDaysAfterRDQMed = pd.DataFrame(index= periodStartsToAnalyze, columns = [1, 10])\n",
        "for i in carDaysAfterRDQMed.index:\n",
        "  for j in carDaysAfterRDQMed.columns:\n",
        "    carDaysAfterRDQMed[j][i] = []\n",
        "\n",
        "#Fill dataframe with arrays of CAR on the last day of the period\n",
        "for m in carDaysAfterRDQMed.index:\n",
        "  for rdqDate in TicOfRDQMedHiLo.index:\n",
        "    #Generate indices for abnormal return dataframe\n",
        "    mDaysAfterRDQStartIndex = str(TicOfRDQMedHiLo['tic'][rdqDate]) + \"/\" + str(rdqDate + m)\n",
        "    mDaysAfterRDQEndIndex = str(TicOfRDQMedHiLo['tic'][rdqDate]) + \"/\" + str(rdqDate + m + periodLength - 1)\n",
        "    #check if indices exist\n",
        "    if (mDaysAfterRDQStartIndex in abnRetMed.index) and (mDaysAfterRDQEndIndex in abnRetMed.index):\n",
        "    periodDF= pd.DataFrame(abnRetMed.loc[mDaysAfterRDQStartIndex: mDaysAfterRDQEndIndex]).reset_index()\n",
        "    #calculate CAR (no need to subtract since first data is included)\n",
        "    periodDF['car'] = periodDF['abn_ret'].cumsum()\n",
        "    carDaysAfterRDQMed[TicOfRDQMedHiLo['sue_decile'][rdqDate]][m].append(periodDF['car'][periodLength - 1])\n",
        "\n",
        "#Take averages of each array to get average CAR on final day\n",
        "for i in carDaysAfterRDQMed.index:\n",
        "  for j in carDaysAfterRDQMed.columns:\n",
        "    #multiply by 100 to get percent value\n",
        "    carDaysAfterRDQMed[j]= np.average(carDaysAfterRDQMed[j][i]) *100\n",
        "\n",
        "\n",
        "print(carDaysAfterRDQMed.columns)\n",
        "print(carDaysAfterRDQMed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hbj59ghQFAz8"
      },
      "outputs": [],
      "source": [
        "#16\n",
        "#Generate CAR Data for 15-Day Periods\n",
        "\n",
        "# Generate CAR Data for Every 60d Period Until Day 480 ###\n",
        "\n",
        "#small Firms\n",
        "#fill new dataframe with empty arrays to get CAR\n",
        "\n",
        "#filter for only highest and lowest sue deciles\n",
        "TicOfRDQSmallHilo= TicOfRDQSmall[(TicOfRDQSmall['sue_decile'] == 1) |(TicOfRDQSmall['sue_decile']==10)]\n",
        "carDaysAfterRDQSmall = pd.DataFrame(index= periodStartsToAnalyze, columns = [1, 10])\n",
        "for i in carDaysAfterRDQSmall.index:\n",
        "  for j in carDaysAfterRDQSmall.columns:\n",
        "    carDaysAfterRDQSmall[j][i] = []\n",
        "\n",
        "#Fill dataframe with arrays of CAR on the last day of the period\n",
        "for m in carDaysAfterRDQSmall.index:\n",
        "  for rdqDate in TicOfRDQSmallHiLo.index:\n",
        "    #Generate indices for abnormal return dataframe\n",
        "    mDaysAfterRDQStartIndex = str(TicOfRDQSmallHiLo['tic'][rdqDate]) + \"/\" + str(rdqDate + m)\n",
        "    mDaysAfterRDQEndIndex = str(TicOfRDQSmallHiLo['tic'][rdqDate]) + \"/\" + str(rdqDate + m + periodLength - 1)\n",
        "    #check if indices exist\n",
        "    if (mDaysAfterRDQStartIndex in abnRetSmall.index) and (mDaysAfterRDQEndIndex in abnRetSmall.index):\n",
        "    periodDF= pd.DataFrame(abnRetMed.loc[mDaysAfterRDQStartIndex: mDaysAfterRDQEndIndex]).reset_index()\n",
        "    #calculate CAR (no need to subtract since first data is included)\n",
        "    periodDF['car'] = periodDF['abn_ret'].cumsum()\n",
        "    carDaysAfterRDQSmall[TicOfRDQSmallHiLo['sue_decile'][rdqDate]][m].append(periodDF['car'][periodLength - 1])\n",
        "\n",
        "#Take averages of each array to get average CAR on final day\n",
        "for i in carDaysAfterRDQSmall.index:\n",
        "  for j in carDaysAfterRDQSmall.columns:\n",
        "    #multiply by 100 to get percent value\n",
        "    carDaysAfterRDQSmall[j]= np.average(carDaysAfterRDQSmall[j][i]) *100\n",
        "\n",
        "\n",
        "print(carDaysAfterRDQSmall.columns)\n",
        "print(carDaysAfterRDQSmall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MFm0j_xa_i15"
      },
      "outputs": [],
      "source": [
        "#17a) Use 15-Day Periods Data to Generate Table 1\n",
        "\n",
        "#Replicate Table 1\n",
        "table1A= pd.DataFrame(index= range(9))\n",
        "table1A[\"holding period\"][\"-59 to -45\", \"-44 to -30\", \"29 to 15\", \"14 to 0\", \"1 to 15\", \"16 to 30\", \"31 to 45\", \"46 to 60\",\"60 to 5\"]\n",
        "#populating array with combos of size and profit\n",
        "for i in [\"s\", \"m\", \"b\"]:\n",
        "  for j in [\"h\", \"l\", \"diff\"]:\n",
        "    table1A[(i + \"/\"+j)]= \"\"\n",
        "\n",
        "#small/high SUE farm\n",
        "for i in range(0, 9):\n",
        "  table1A['s/h'][i]= carDaysAfterRDQSmall[10][(i-4)* 15+1]\n",
        "\n",
        "#small/low SUE farm\n",
        "for i in range(0, 9):\n",
        "  table1A['s/l'][i]= carDaysAfterRDQSmall[10][(i-4)* 15+1]\n",
        "\n",
        "#small/diff SUE\n",
        "table1A['s/diff']= table1A['s/h']- table1A['s/l']\n",
        "\n",
        "\n",
        "print(table1A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YK5icnKGIKEQ"
      },
      "outputs": [],
      "source": [
        "#medium/high SUE farm\n",
        "for i in range(0, 9):\n",
        "  table1A['m/h'][i]= carDaysAfterRDQMed[10][(i-4)* 15+1]\n",
        "\n",
        "#medium/low SUE farm\n",
        "for i in range(0, 9):\n",
        "  table1A['m/l'][i]= carDaysAfterRDQMed[10][(i-4)* 15+1]\n",
        "\n",
        "#medium/diff SUE\n",
        "table1A['m/diff']= table1A['m/h']- table1A['m/l']\n",
        "\n",
        "print(table1A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7n8IVXckIMyU"
      },
      "outputs": [],
      "source": [
        "#big/high SUE farm\n",
        "for i in range(0, 9):\n",
        "  table1A['b/h'][i]= carDaysAfterRDQBig[10][(i-4)* 15+1]\n",
        "\n",
        "#big/low SUE farm\n",
        "for i in range(0, 9):\n",
        "  table1A['b/l'][i]= carDaysAfterRDQBig[10][(i-4)* 15+1]\n",
        "\n",
        "#big/diff SUE\n",
        "table1A['b/diff']= table1A['b/h']- table1A['b/l']\n",
        "\n",
        "print(table1A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNH0KYeqJJvm"
      },
      "source": [
        "Generate 30 and 60 day CAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O8NP9pqx_qdd"
      },
      "outputs": [],
      "source": [
        "#18. Generate 30-Day/60-Day CAR with Date\n",
        "\n",
        "#Extreme GN/BN FIRMS: Generate 30-day Cumulative Abnormal Returns with Different Method Including Date of Data for Table 3 sus\n",
        "\n",
        "mainDF= originalMain\n",
        "\n",
        "mainDFHiLo= mainDF[(mainDF['sue_decile'] == 1)| (mainDF['sue_decile'] == 10)]\n",
        "\n",
        "#Generate new dataframe with tic, SUE decile, and size decile on RDQ\n",
        "TicOfRDQHiLo= mainDFHiLo.dropna() #drop null values (null RDQs or null SUE decile (1st quarter of data))\n",
        "TicOfRDQHiLo= TicOfRDQHiLo.filter(['tic', 'sue_decile', 'size_decile']) #new dataframe with only tic, SUE decile, and size decile\n",
        "\n",
        "#Generate new groupby variable of abnormal return with tic and original_index as indices\n",
        "abnRetHiLo= mainDFHiLo.reset_index() #generate new index to pop original one out as index'\n",
        "abnRetHiLo.columns= [['original_index', 'tic', 'date', 'datadate', 'year', 'qtr', 'ret', 'rdq', 'size_decile', 'avg_ret', 'abn_ret', 'sue','sue_decile']]\n",
        "#group by tic and original_index and make them the new indicies\n",
        "abnRetHilo= abnRetHiLo.groupby(['tic', 'original_index'], as_index= False)['abn_ret'].first()\n",
        "abnRetHiLo['new_index'] = abnRetHiLo['tic'].apply(str)+\"/\"+abnRetHiLo['original_index'].apply(str)\n",
        "abnRetHilo= abnRetHiLo.set_index('new_index')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RyzuuLt_LRb9"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Create new dataframes to store CAR around RDQ\n",
        "car30dHiLoWithDates= mainDF.filter(['tic', 'date', 'sue_decile'])\n",
        "car30dHiLoWithDates['days_after_rdq'] = \"\"\n",
        "car30dHiLoWithDates['car']=\"\"\n",
        "\n",
        "car60dHiLoWithDates= mainDF.filter(['tic', 'date', 'sue_decile'])\n",
        "car60dHiLoWithDates['days_after_rdq']= \"\"\n",
        "car60dHiLoWithDates['car']= \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RW3ENk51_s-4"
      },
      "outputs": [],
      "source": [
        "#18 (cont).\n",
        "#Generate 30-Day/60-Day CAR with Date\n",
        "\n",
        "#Calculate CAR and store them in corresponding SUE Deciles\n",
        "n=30 #set to number of days before/after RDQ to be analyzed\n",
        "for rdqDate in TicofRDQHiLo.index:\n",
        "  #Generate indices for abnormal return dataframe\n",
        "  rdqDateIndex= str(TicofRDQHiLo['tic'][rdqDate])+\"/\"+ str(rdqDate)\n",
        "  nDaysAfterIndex= str(TicOfRDQHiLo['tic'][rdqDate])+\"/\"+ str(rdqDate + n)\n",
        "\n",
        "  #check if n days after RDQ abnormal return\n",
        "  if nDaysAfterIndex in abnRetHiLo.index:\n",
        "    #Add n days after CAR\n",
        "    afterDF= pd.DataFrame(abnRet.loc[rdqDateIndex: nDaysAfterIndex]).reset_index()\n",
        "    #calculate CAR (sum of all abn_ret first abn_ret)\n",
        "    afterDF['car'] = afterDF['abn_ret'].cumsum()- afterDF['abn_ret'][0]\n",
        "    car30dHiLoWithDates['days_after_rdq'][rdqDate: rdqDate + n + 1]= afterDF.index\n",
        "    car30dHiLoWithDates['car'][rdqDate: rdqDate + n + 1]= afterDF['car']\n",
        "\n",
        "\n",
        "print(car30dHiLoWithDates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b-zq366JNIXD"
      },
      "outputs": [],
      "source": [
        "#Calculate CAR and store them in corresponding SUE Deciles\n",
        "m=60 #set to number of days before/after RDQ to be analyzed\n",
        "for rdqDate in TicofRDQHiLo.index:\n",
        "  #Generate indices for abnormal return dataframe\n",
        "  rdqDateIndex= str(TicofRDQHiLo['tic'][rdqDate])+\"/\"+ str(rdqDate)\n",
        "  nDaysAfterIndex= str(TicOfRDQHiLo['tic'][rdqDate])+\"/\"+ str(rdqDate + n)\n",
        "\n",
        "  #check if n days after RDQ abnormal return\n",
        "  if nDaysAfterIndex in abnRetHiLo.index:\n",
        "    #Add n days after CAR\n",
        "    afterDF= pd.DataFrame(abnRet.loc[rdqDateIndex: nDaysAfterIndex]).reset_index()\n",
        "    #calculate CAR (sum of all abn_ret first abn_ret)\n",
        "    afterDF['car'] = afterDF['abn_ret'].cumsum()- afterDF['abn_ret'][0]\n",
        "    car60dHiLoWithDates['days_after_rdq'][rdqDate: rdqDate + m + 1]= afterDF.index\n",
        "    car60dHiLoWithDates['car'][rdqDate: rdqDate + m + 1]= afterDF['car']\n",
        "\n",
        "\n",
        "print(car60dHiLoWithDates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IHqJhsjoNkpe"
      },
      "outputs": [],
      "source": [
        "car30dHiLoWithDates['car'] *= 100\n",
        "car30dHiLoWithDates= car30dHiLowithDates[car30dHiLowithDates['days_after_rdq'] ==30]\n",
        "print(car30dHiLoWithDates)\n",
        "\n",
        "car60dHiLoWithDates['car'] *= 100\n",
        "car60dHiLoWithDates= car60dHiLoWithDates[car60dHiLoWithDates['days_after_rdq'] ==60]\n",
        "print(car60dHiLoWithDates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob8S5BcNN9yD"
      },
      "source": [
        "replicate table 3 with 30d data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MkayKftGN8xF"
      },
      "outputs": [],
      "source": [
        "file = \"/content/drive/MyDrive/Exeter google drive /internships jobs/FIMA '23/Post earnings announcement drift PEAD/F-F_Research_Data_5_Factors_Daily.csv\"\n",
        "ffDF = pd.read_csv(file)\n",
        "print(ffDF.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "h8UqEzTuSUqf"
      },
      "outputs": [],
      "source": [
        "#Convert variables.\n",
        "ffDF['Date'] = pd.to_datetime(ffDF['Date'], format = '%Y%m%d')\n",
        "ffDF['Mkt-RF']= pd.to_numeric(ffDF['Mkt-RF'], errors= 'coerce')\n",
        "ffDF['SMB']= pd.to_numeric(ffDF['SMB'], errors= 'coerce')\n",
        "ffDF['HML']= pd.to_numeric(ffDF['HML'], errors= 'coerce')\n",
        "ffDF['RMW']= pd.to_numeric(ffDF['RMW'], errors= 'coerce')\n",
        "ffDF['CMA']= pd.to_numeric(ffDF['CMA'], errors= 'coerce')\n",
        "ffDF['RF']= pd.to_numeric(ffDF['RF'], errors= 'coerce')\n",
        "\n",
        "#Add MKT column (not adjusted for treasury bills)\n",
        "ffDF['mkt']= ffDF['Mkt-RF']+ ffDF['RF']\n",
        "\n",
        "#Rename columns\n",
        "ffDF.columns= [['date', 'rm_minus_rf', 'smb', 'hml', 'cma', 'rf', 'mkt']]\n",
        "\n",
        "#Only keep data after 2019\n",
        "ffDF= ffDF[ffDF['date'] >= \"2019-01-01\"]\n",
        "\n",
        "print(ffDf.columns)\n",
        "print(ffDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Jtp1YJrUS0Qq"
      },
      "outputs": [],
      "source": [
        "#Left Join FF into car30dHiLoWithDates\n",
        "car30dHiLoWithDates= car30dHiLoWithDates.merge(ffDF, how='left', on= ['date'])\n",
        "\n",
        "print(car30dHiLoWithDates.columns)\n",
        "print(car30dHiLoWithDates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jz-6-kVCS2cP"
      },
      "outputs": [],
      "source": [
        "#Generate table with ols reggression line of best fit\n",
        "#dependent= car\n",
        "#independent= all the other factors\n",
        "table3A= sm.ols(\"car~ rm_minus_rf + smb+ hml +rmw+ cma\", data= car30dHiLoWithDates).fit()\n",
        "table3ASummary = table3A.summary()\n",
        "\n",
        "table3B= sm.ols(\"car~ smb+ hml +rmw+ cma+ mkt\",  data= car30dHiLoWithDates).fit()\n",
        "table3BSummary= table3B.summary()\n",
        "\n",
        "print(table3ASummary)\n",
        "print(table3BSummary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4XDha3pXS3u"
      },
      "source": [
        "Figure 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SL2vQ7Fv_zRa"
      },
      "outputs": [],
      "source": [
        "#20.\n",
        "#Replicate Figure 5 with 60D Data\n",
        "\n",
        "#replicate Figure\n",
        "\n",
        "car60HiLowithDates['year']= car60HiLowithDates['date'].dt.year\n",
        "car60HiLowithDates['qtr']= np.cell(car60HiLowithDates['date'].dt.month/3)\n",
        "car60HiLowithDates['year/qtr']= car60HiLowithDates['year'].astype(str)+/+ car60HiLowithDates['qtr'].astype(str)\n",
        "\n",
        "car60HiLowithDates[car60HiLowithDates['days after rdq']  == 60]\n",
        "car60ByYearQtr= car60HiLowithDates.groupby('year/qtr', as Index= False)['car'].mean()\n",
        "\n",
        "plotcar60ByYearQtr= car60ByYearQtr.plot(x= 'year/qtr', y='car', kind-\"bar\", figsize=[15, 10], title \"Figure 5: CAR vs. Year/QTR of Data\")\n",
        "plotCAR6edByYearQtr.set_xlabel(\"Year/QTR\")\n",
        "plotcar60ByYearQtr.set_ylabel(\"Cumulative Abnormal Return (%)\")\n",
        "\n",
        "fig= plotcar60ByYearQtr.get_figure()\n",
        "fig.savefig(filePath\"/plotcar60ByYearQtr.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnadKAohZ_wO"
      },
      "source": [
        "#21.\n",
        "#Generate Raw Return Data for Each portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qerUazhGZ8dP"
      },
      "outputs": [],
      "source": [
        "\n",
        "maindf=originalMain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7fO_7wY4caz7"
      },
      "outputs": [],
      "source": [
        "#Generate Dataframes for Each Portfolios Again for Raw Returns Instead of CAR\n",
        "#Generate mainDFs for each portfolio\n",
        "\n",
        "maindflo= maindf[maindf['sue_decile']== 1]\n",
        "maindfloSmall= maindflo[maindflo['size_decile'] <= 4]\n",
        "maindfloMed= maindflo[(maindflo['size_decile'] >= 5) & (maindflo['size_decile']<= 7)]\n",
        "maindfloBig= maindflo[maindflo['size_decile']>= 8]\n",
        "\n",
        "maindfHi= mainDF[mainDF['sue_decile']== 10]\n",
        "maindfHiSmall= maindfHi[maindfHi['size_decile']<= 4]\n",
        "maindfHiMed= maindfHi[(maindfHi['size_decile']>= 5) & (maindfHi['size_decile'] <= 7)]\n",
        "maindfHiBig= maindfHi[maindfHi['size_decile'] >= 8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TcF2BNpFXWhX"
      },
      "outputs": [],
      "source": [
        "#Generate TicoFRDQ and raw return dataframes for each portfolio\n",
        "#s/l\n",
        "ticofRDQLoSmall= maindfloSmall.dropna()\n",
        "ticofRDQLoSmall= ticofRDQLoSmall.filter(['tic', 'sue_decile', 'size_decile'])\n",
        "rawretLoSmall= maindf.reset_index()\n",
        "rawretLoSmall.columns[['original_index', 'tic', 'date', 'datadate', 'year', 'qtr', 'ret', 'rdq', 'size_decile', 'avg_ret', 'avg_ret', 'sue', 'sue_decile']]\n",
        "rawretLoSmall= rawretLoSmall.groupby(['tic', 'original_index'], as index= False)['ret'].first()\n",
        "rawretLoSmall['new index']= rawretLoSmall['tic'].astype(str)+\"/\"+rawretLoSmall['original_index'].astype(str)\n",
        "rawretLoSmall= rawretLoSmall.set_index(\"new_index\")\n",
        "\n",
        "#m/l\n",
        "ticofRDQLoMed= maindfloMed.dropna()\n",
        "ticofRDQLoMed= ticofRDQLoMed.filter(['tic', 'sue_decile', 'size_decile'])\n",
        "rawretLoMedl= maindf.reset_index()\n",
        "rawretLoMedl.columns[['original_index', 'tic', 'date', 'datadate', 'year', 'qtr', 'ret', 'rdq', 'size_decile', 'avg_ret', 'avg_ret', 'sue', 'sue_decile']]\n",
        "rawretLoMedl= rawretLoMedl.groupby(['tic', 'original_index'], as index= False)['ret'].first()\n",
        "rawretLoMedl['new index']= rawretLoMedl['tic'].astype(str)+\"/\"+rawretLoMedl['original_index'].astype(str)\n",
        "rawretLoMedl= rawretLoMedl.set_index(\"new_index\")\n",
        "\n",
        "#b/l\n",
        "ticofRDQLoBig= maindfloBig.dropna()\n",
        "ticofRDQLoBig= ticofRDQLoBig.filter(['tic', 'sue_decile', 'size_decile'])\n",
        "rawretLoBig= maindf.reset_index()\n",
        "rawretLoBig.columns[['original_index', 'tic', 'date', 'datadate', 'year', 'qtr', 'ret', 'rdq', 'size_decile', 'avg_ret', 'avg_ret', 'sue', 'sue_decile']]\n",
        "rawretLoBig= rawretLoBig.groupby(['tic', 'original_index'], as index= False)['ret'].first()\n",
        "rawretLoBig['new index']= rawretLoBig['tic'].astype(str)+\"/\"+rawretLoBig['original_index'].astype(str)\n",
        "rawretLoBig= rawretLoBig.set_index(\"new_index\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IBKjeFmremET"
      },
      "outputs": [],
      "source": [
        "#s/h\n",
        "ticofRDQHiSmall= maindfHiSmall.dropna()\n",
        "ticofRDQHiSmall= ticofRDQHiSmall.filter(['tic', 'sue_decile', 'size_decile'])\n",
        "rawretHiSmall= maindf.reset_index()\n",
        "rawretHiSmall.columns[['original_index', 'tic', 'date', 'datadate', 'year', 'qtr', 'ret', 'rdq', 'size_decile', 'avg_ret', 'avg_ret', 'sue', 'sue_decile']]\n",
        "rawretHiSmall= rawretLoSmall.groupby(['tic', 'original_index'], as index= False)['ret'].first()\n",
        "rawretHiSmall['new index']= rawretHiSmall['tic'].astype(str)+\"/\"+rawretHiSmall['original_index'].astype(str)\n",
        "rawretHiSmall= rawretHiSmall.set_index(\"new_index\")\n",
        "\n",
        "\n",
        "\n",
        "#m/h\n",
        "ticofRDQHiMed= maindfHiMed.dropna()\n",
        "ticofRDQHiMed= ticofRDQHiMed.filter(['tic', 'sue_decile', 'size_decile'])\n",
        "rawretHiMed= maindf.reset_index()\n",
        "rawretHiMed.columns[['original_index', 'tic', 'date', 'datadate', 'year', 'qtr', 'ret', 'rdq', 'size_decile', 'avg_ret', 'avg_ret', 'sue', 'sue_decile']]\n",
        "rawretHiMed= rawretHiMed.groupby(['tic', 'original_index'], as index= False)['ret'].first()\n",
        "rawretHiMed['new index']= rawretHiMed['tic'].astype(str)+\"/\"+rawretHiMed['original_index'].astype(str)\n",
        "rawretHiMed= rawretHiMed.set_index(\"new_index\")\n",
        "\n",
        "#b/h\n",
        "ticofRDQHiBig= maindfHiBig.dropna()\n",
        "ticofRDQHiBig= ticofRDQHiBig.filter(['tic', 'sue_decile', 'size_decile'])\n",
        "rawretHiBig= maindf.reset_index()\n",
        "rawretHiBig.columns[['original_index', 'tic', 'date', 'datadate', 'year', 'qtr', 'ret', 'rdq', 'size_decile', 'avg_ret', 'avg_ret', 'sue', 'sue_decile']]\n",
        "rawretHiBig= rawretHiBig.groupby(['tic', 'original_index'], as index= False)['ret'].first()\n",
        "rawretHiBig['new index']= rawretHiBig['tic'].astype(str)+\"/\"+rawretHiBig['original_index'].astype(str)\n",
        "rawretHiBig= rawretHiBig.set_index(\"new_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4pDo_4MfXZMo"
      },
      "outputs": [],
      "source": [
        "#Starting and ending days of periods to calculate raw returns\n",
        "startingDays= [1, 6, 21, 41, 61]\n",
        "endingDays= [5, 20, 40, 60, 80]\n",
        "\n",
        "# #fill new dataframe with empty arrays to get CRR for S/L Portfolio\n",
        "# avgCRRLOSmall= pd.DataFrame(index startingDays, columns = ['crr'])\n",
        "# for i in avgCRRLOSmall.index:\n",
        "#   for j in avgCRRLOSmall.columns\n",
        "#   avgCRRLOSmall[i][j]= []\n",
        "\n",
        "#optimized- you can initialize df by using a lambda function\n",
        "# Initialize DataFrame to store CRR for S/L Portfolio\n",
        "avgCRRLoSmall = pd.DataFrame(index=startingDays, columns=['crr'], dtype=object)\n",
        "avgCRRLoSmall['crr'] = avgCRRLoSmall['crr'].apply(lambda x: [])\n",
        "\n",
        "\n",
        "# Fill DataFrame with cumulative raw return (CRR) data\n",
        "for i in range(len(startingDays)):\n",
        "    a = startingDays[i]\n",
        "    b = endingDays[i]\n",
        "    for rdqDate in ticofRDQLoSmall.index:\n",
        "        # Generate indices for abnormal return dataframe\n",
        "        startIndex = str(ticofRDQLoSmall['tic'][rdqDate]) + \"/\" + str(rdqDate + a)\n",
        "        endIndex = str(ticofRDQLoSmall['tic'][rdqDate]) + \"/\" + str(rdqDate + b)\n",
        "\n",
        "        if (startIndex in rawretLoSmall.index) and (endIndex in rawretLoSmall.index):\n",
        "            # Get period data and calculate CRR\n",
        "            periodDF = rawretLoSmall.loc[startIndex:endIndex].reset_index()\n",
        "            periodDF['crr'] = periodDF['ret'].cumsum()\n",
        "\n",
        "            # Append average CRR on the final day to the DataFrame\n",
        "            avgCRRLoSmall['crr'][a].append(periodDF['crr'][b - a].mean())\n",
        "\n",
        "\n",
        "# for i in avgCRRLoSmall.index:\n",
        "#   #multiply by 100 to get percent value\n",
        "#   avgCRRLoSmall['crr'][i]= np.average(avgCRRLoSmall['crr'][i])* 100\n",
        "\n",
        "#optimization:  a 1:1 for loop to lambda function\n",
        "# Convert lists of CRRs to numpy arrays and calculate average CRRs\n",
        "avgCRRLoSmall['crr'] = avgCRRLoSmall['crr'].apply(lambda x: np.mean(x) * 100)\n",
        "\n",
        "print(avgCRRLoSmall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CLfLhiBtk6kE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#optimized- you can initialize df by using a lambda function\n",
        "# Initialize DataFrame to store CRR for S/L Portfolio\n",
        "avgCRRLoMed = pd.DataFrame(index=startingDays, columns=['crr'], dtype=object)\n",
        "avgCRRLoMed['crr'] = avgCRRLoMed['crr'].apply(lambda x: [])\n",
        "\n",
        "\n",
        "# Fill DataFrame with cumulative raw return (CRR) data\n",
        "for i in range(len(startingDays)):\n",
        "    a = startingDays[i]\n",
        "    b = endingDays[i]\n",
        "    for rdqDate in ticofRDQLoMed.index:\n",
        "        # Generate indices for abnormal return dataframe\n",
        "        startIndex = str(ticofRDQLoMed['tic'][rdqDate]) + \"/\" + str(rdqDate + a)\n",
        "        endIndex = str(ticofRDQLoMed['tic'][rdqDate]) + \"/\" + str(rdqDate + b)\n",
        "\n",
        "        if (startIndex in rawretLoMed.index) and (endIndex in rawretLoMed.index):\n",
        "            # Get period data and calculate CRR\n",
        "            periodDF = rawretLoMed.loc[startIndex:endIndex].reset_index()\n",
        "            periodDF['crr'] = periodDF['ret'].cumsum()\n",
        "\n",
        "            # Append average CRR on the final day to the DataFrame\n",
        "            avgCRRLoMed['crr'][a].append(periodDF['crr'][b - a].mean())\n",
        "\n",
        "\n",
        "# for i in avgCRRLoSmall.index:\n",
        "#   #multiply by 100 to get percent value\n",
        "#   avgCRRLoSmall['crr'][i]= np.average(avgCRRLoSmall['crr'][i])* 100\n",
        "\n",
        "#optimization:  a 1:1 for loop to lambda function\n",
        "# Convert lists of CRRs to numpy arrays and calculate average CRRs\n",
        "avgCRRLoMed['crr'] = avgCRRLoMed['crr'].apply(lambda x: np.mean(x) * 100)\n",
        "\n",
        "print(avgCRRLoMed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XpwYLaeyk_aE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#optimized- you can initialize df by using a lambda function\n",
        "# Initialize DataFrame to store CRR for S/L Portfolio\n",
        "avgCRRLoBig = pd.DataFrame(index=startingDays, columns=['crr'], dtype=object)\n",
        "avgCRRLoBig['crr'] = avgCRRLoBig['crr'].apply(lambda x: [])\n",
        "\n",
        "\n",
        "# Fill DataFrame with cumulative raw return (CRR) data\n",
        "for i in range(len(startingDays)):\n",
        "    a = startingDays[i]\n",
        "    b = endingDays[i]\n",
        "    for rdqDate in ticofRDQLoBig.index:\n",
        "        # Generate indices for abnormal return dataframe\n",
        "        startIndex = str(ticofRDQLoBig['tic'][rdqDate]) + \"/\" + str(rdqDate + a)\n",
        "        endIndex = str(ticofRDQLoBig['tic'][rdqDate]) + \"/\" + str(rdqDate + b)\n",
        "\n",
        "        if (startIndex in rawretLoBig.index) and (endIndex in rawretLoBig.index):\n",
        "            # Get period data and calculate CRR\n",
        "            periodDF = rawretLoBig.loc[startIndex:endIndex].reset_index()\n",
        "            periodDF['crr'] = periodDF['ret'].cumsum()\n",
        "\n",
        "            # Append average CRR on the final day to the DataFrame\n",
        "            avgCRRLoBig['crr'][a].append(periodDF['crr'][b - a].mean())\n",
        "\n",
        "\n",
        "# for i in avgCRRLoSmall.index:\n",
        "#   #multiply by 100 to get percent value\n",
        "#   avgCRRLoSmall['crr'][i]= np.average(avgCRRLoSmall['crr'][i])* 100\n",
        "\n",
        "#optimization:  a 1:1 for loop to lambda function\n",
        "# Convert lists of CRRs to numpy arrays and calculate average CRRs\n",
        "avgCRRLoBig['crr'] = avgCRRLoBig['crr'].apply(lambda x: np.mean(x) * 100)\n",
        "\n",
        "print(avgCRRLoBig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KVsGxvzsk_47"
      },
      "outputs": [],
      "source": [
        "\n",
        "#optimized- you can initialize df by using a lambda function\n",
        "# Initialize DataFrame to store CRR for S/L Portfolio\n",
        "avgCRRHiSmall = pd.DataFrame(index=startingDays, columns=['crr'], dtype=object)\n",
        "avgCRRHiSmall['crr'] = avgCRRHiSmall['crr'].apply(lambda x: [])\n",
        "\n",
        "\n",
        "# Fill DataFrame with cumulative raw return (CRR) data\n",
        "for i in range(len(startingDays)):\n",
        "    a = startingDays[i]\n",
        "    b = endingDays[i]\n",
        "    for rdqDate in ticofRDQHiSmall.index:\n",
        "        # Generate indices for abnormal return dataframe\n",
        "        startIndex = str(ticofRDQHiSmall['tic'][rdqDate]) + \"/\" + str(rdqDate + a)\n",
        "        endIndex = str(ticofRDQHiSmall['tic'][rdqDate]) + \"/\" + str(rdqDate + b)\n",
        "\n",
        "        if (startIndex in rawretHiSmall.index) and (endIndex in rawretHiSmall.index):\n",
        "            # Get period data and calculate CRR\n",
        "            periodDF = rawretHiSmall.loc[startIndex:endIndex].reset_index()\n",
        "            periodDF['crr'] = periodDF['ret'].cumsum()\n",
        "\n",
        "            # Append average CRR on the final day to the DataFrame\n",
        "            avgCRRHiSmall['crr'][a].append(periodDF['crr'][b - a].mean())\n",
        "\n",
        "\n",
        "# for i in avgCRRLoSmall.index:\n",
        "#   #multiply by 100 to get percent value\n",
        "#   avgCRRLoSmall['crr'][i]= np.average(avgCRRLoSmall['crr'][i])* 100\n",
        "\n",
        "#optimization:  a 1:1 for loop to lambda function\n",
        "# Convert lists of CRRs to numpy arrays and calculate average CRRs\n",
        "avgCRRHiSmall['crr'] = avgCRRHiSmall['crr'].apply(lambda x: np.mean(x) * 100)\n",
        "\n",
        "print(avgCRRHiSmall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6DNISz_OlALw"
      },
      "outputs": [],
      "source": [
        "\n",
        "#optimized- you can initialize df by using a lambda function\n",
        "# Initialize DataFrame to store CRR for S/L Portfolio\n",
        "avgCRRHiMed = pd.DataFrame(index=startingDays, columns=['crr'], dtype=object)\n",
        "avgCRRHiMed['crr'] = avgCRRHiMed['crr'].apply(lambda x: [])\n",
        "\n",
        "\n",
        "# Fill DataFrame with cumulative raw return (CRR) data\n",
        "for i in range(len(startingDays)):\n",
        "    a = startingDays[i]\n",
        "    b = endingDays[i]\n",
        "    for rdqDate in ticofRDQHiMed.index:\n",
        "        # Generate indices for abnormal return dataframe\n",
        "        startIndex = str(ticofRDQHiMed['tic'][rdqDate]) + \"/\" + str(rdqDate + a)\n",
        "        endIndex = str(ticofRDQHiMed['tic'][rdqDate]) + \"/\" + str(rdqDate + b)\n",
        "\n",
        "        if (startIndex in rawretHiMed.index) and (endIndex in rawretHiMed.index):\n",
        "            # Get period data and calculate CRR\n",
        "            periodDF = rawretHiMed.loc[startIndex:endIndex].reset_index()\n",
        "            periodDF['crr'] = periodDF['ret'].cumsum()\n",
        "\n",
        "            # Append average CRR on the final day to the DataFrame\n",
        "            avgCRRHiMed['crr'][a].append(periodDF['crr'][b - a].mean())\n",
        "\n",
        "\n",
        "# for i in avgCRRLoSmall.index:\n",
        "#   #multiply by 100 to get percent value\n",
        "#   avgCRRLoSmall['crr'][i]= np.average(avgCRRLoSmall['crr'][i])* 100\n",
        "\n",
        "#optimization:  a 1:1 for loop to lambda function\n",
        "# Convert lists of CRRs to numpy arrays and calculate average CRRs\n",
        "avgCRRHiMed['crr'] = avgCRRHiMed['crr'].apply(lambda x: np.mean(x) * 100)\n",
        "\n",
        "print(avgCRRHiMed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a2VfKWGmlAl9"
      },
      "outputs": [],
      "source": [
        "\n",
        "#optimized- you can initialize df by using a lambda function\n",
        "# Initialize DataFrame to store CRR for S/L Portfolio\n",
        "avgCRRHiBig = pd.DataFrame(index=startingDays, columns=['crr'], dtype=object)\n",
        "avgCRRHiBig['crr'] = avgCRRHiBig['crr'].apply(lambda x: [])\n",
        "\n",
        "\n",
        "# Fill DataFrame with cumulative raw return (CRR) data\n",
        "for i in range(len(startingDays)):\n",
        "    a = startingDays[i]\n",
        "    b = endingDays[i]\n",
        "    for rdqDate in ticofRDQHiBig.index:\n",
        "        # Generate indices for abnormal return dataframe\n",
        "        startIndex = str(ticofRDQHiBig['tic'][rdqDate]) + \"/\" + str(rdqDate + a)\n",
        "        endIndex = str(ticofRDQHiBig['tic'][rdqDate]) + \"/\" + str(rdqDate + b)\n",
        "\n",
        "        if (startIndex in rawretHiBig.index) and (endIndex in rawretHiBig.index):\n",
        "            # Get period data and calculate CRR\n",
        "            periodDF = rawretHiBig.loc[startIndex:endIndex].reset_index()\n",
        "            periodDF['crr'] = periodDF['ret'].cumsum()\n",
        "\n",
        "            # Append average CRR on the final day to the DataFrame\n",
        "            avgCRRHiBig['crr'][a].append(periodDF['crr'][b - a].mean())\n",
        "\n",
        "\n",
        "# for i in avgCRRLoSmall.index:\n",
        "#   #multiply by 100 to get percent value\n",
        "#   avgCRRLoSmall['crr'][i]= np.average(avgCRRLoSmall['crr'][i])* 100\n",
        "\n",
        "#optimization:  a 1:1 for loop to lambda function\n",
        "# Convert lists of CRRs to numpy arrays and calculate average CRRs\n",
        "avgCRRHiBig['crr'] = avgCRRHiBig['crr'].apply(lambda x: np.mean(x) * 100)\n",
        "\n",
        "print(avgCRRHiBig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlz0PBc6mMIT"
      },
      "source": [
        "22a) Replicate Table 4 with Raw Return Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mE6kKQ_Ana_l"
      },
      "outputs": [],
      "source": [
        "Table4A= pd.DataFrame(index= startingDays)\n",
        "Table4A['postannouncement_period']=['(1, 5)', '(6, 20)', '(21, 40)', '(41, 60)', '(61, 80)']\n",
        "#why only for low and not high?\n",
        "Table4A['s/l_rr']= avgCRRLoSmall['crr']\n",
        "Table4A['s/l_crr']= Table4A['s/l_rr'].cumsum()\n",
        "\n",
        "Table4A['m/l_rr']= avgCRRMedSmall['crr']\n",
        "Table4A['m/l_crr']= Table4A['m/l_rr'].cumsum()\n",
        "\n",
        "Table4A['h/l_rr']= avgCRRHiSmall['crr']\n",
        "Table4A['h/l_crr']= Table4A['h/l_rr'].cumsum()\n",
        "\n",
        "print(Table4A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MrBCcDjtpDAD"
      },
      "outputs": [],
      "source": [
        "Table4B= pd.DataFrame(index= startingDays)\n",
        "Table4B['postannouncement_period']=['(1, 5)', '(6, 20)', '(21, 40)', '(41, 60)', '(61, 80)']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gJWPc-oCpFdj"
      },
      "outputs": [],
      "source": [
        "\n",
        "Table4B['s/l_crr_annualized']= \"\"\n",
        "Table4B['s/l_crr_annualized'][1] *= 252 / 5\n",
        "Table4B['s/l_crr_annualized'][6] *= 252 / 20\n",
        "Table4B['s/l_crr_annualized'][21] *= 252 / 40\n",
        "Table4B['s/l_crr_annualized'][41] *= 252 / 60\n",
        "Table4B['s/l_crr_annualized'][61] *= 252 / 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uBH9HXoVpFsK"
      },
      "outputs": [],
      "source": [
        "\n",
        "Table4B['m/l_crr_annualized']= \"\"\n",
        "Table4B['m/l_crr_annualized'][1] *= 252 / 5\n",
        "Table4B['m/l_crr_annualized'][6] *= 252 / 20\n",
        "Table4B['m/l_crr_annualized'][21] *= 252 / 40\n",
        "Table4B['m/l_crr_annualized'][41] *= 252 / 60\n",
        "Table4B['m/l_crr_annualized'][61] *= 252 / 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_UmKjUItpFzN"
      },
      "outputs": [],
      "source": [
        "\n",
        "Table4B['b/l_crr_annualized']= \"\"\n",
        "Table4B['b/l_crr_annualized'][1] *= 252 / 5\n",
        "Table4B['b/l_crr_annualized'][6] *= 252 / 20\n",
        "Table4B['b/l_crr_annualized'][21] *= 252 / 40\n",
        "Table4B['b/l_crr_annualized'][41] *= 252 / 60\n",
        "Table4B['b/l_crr_annualized'][61] *= 252 / 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4WdUNYnGpF5N"
      },
      "outputs": [],
      "source": [
        "\n",
        "Table4B['s/h_crr_annualized']= \"\"\n",
        "Table4B['s/h_crr_annualized']= avgCRRHiSmall.cumsum()\n",
        "Table4B['s/h_crr_annualized'][1] *= 252 / 5\n",
        "Table4B['s/h_crr_annualized'][6] *= 252 / 20\n",
        "Table4B['s/h_crr_annualized'][21] *= 252 / 40\n",
        "Table4B['s/h_crr_annualized'][41] *= 252 / 60\n",
        "Table4B['s/h_crr_annualized'][61] *= 252 / 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dIvq1_L2pF-l"
      },
      "outputs": [],
      "source": [
        "\n",
        "Table4B['m/h_crr_annualized']= \"\"\n",
        "Table4B['m/h_crr_annualized']= avgCRRHiMed.cumsum()\n",
        "Table4B['m/h_crr_annualized'][1] *= 252 / 5\n",
        "Table4B['m/h_crr_annualized'][6] *= 252 / 20\n",
        "Table4B['m/h_crr_annualized'][21] *= 252 / 40\n",
        "Table4B['m/h_crr_annualized'][41] *= 252 / 60\n",
        "Table4B['m/h_crr_annualized'][61] *= 252 / 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EtnlrBK9XfFZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "Table4B['b/h_crr_annualized']= \"\"\n",
        "Table4B['b/h_crr_annualized']= avgCRRHiBig.cumsum()\n",
        "Table4B['b/h_crr_annualized'][1] *= 252 / 5\n",
        "Table4B['b/h_crr_annualized'][6] *= 252 / 20\n",
        "Table4B['b/h_crr_annualized'][21] *= 252 / 40\n",
        "Table4B['b/h_crr_annualized'][41] *= 252 / 60\n",
        "Table4B['b/h_crr_annualized'][61] *= 252 / 80\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3CEuL390sPpD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "print(Table4B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_g1zZ35tfnV"
      },
      "source": [
        "23. Replicate table 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0sAC0O74tlYY"
      },
      "outputs": [],
      "source": [
        "#checkpoint\n",
        "mainDF= originalMain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "efvt0gN2t0cQ"
      },
      "outputs": [],
      "source": [
        "ffDF= ffDF[['date','rm_minus_rf', 'rf']]\n",
        "print(ffDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uSyAbjCZtpJe"
      },
      "outputs": [],
      "source": [
        "mainDF= mainDF.merge(ffDF, how= 'left', on='date')\n",
        "print(mainDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "R3Pp7SYcuFt6"
      },
      "outputs": [],
      "source": [
        "#convert to decimal\n",
        "mainDF['rm_minus_rf']/=100\n",
        "mainDF['rf']/= 100\n",
        "mainDF.drop('index', inplace= True, axis=1)\n",
        "print(mainDF.columns)\n",
        "print(mainDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wmmGZvSQXhU3"
      },
      "outputs": [],
      "source": [
        "#create starting days and ending days arrays\n",
        "startingDays= [-119, -59, 1, 61, 121, 181]\n",
        "endingDays= [-60,0,60,120,180,240]\n",
        "\n",
        "#refine new function to calculate compounded total returns\n",
        "def calculateCumRawRetCompounded(startingDay, endingDay, ticsToAnalyze):\n",
        "  cumRetMinusCumRF= []\n",
        "  cumRMMinusRF= []\n",
        "  for i in ticsToAnalyze.index:\n",
        "  #Generate indices for abnormal return dataframe\n",
        "    startIndex= i+ startingDay\n",
        "    endIndex= i+ endingDay\n",
        "    #what is 'checking to see if there is an index\n",
        "    if((startIndex in mainDF.index) and (mainDF['tic'][startIndex]) ==ticsToAnalyze['tic'][i]) and ((endIndex In mainDF.index) and (mainDF['tic'][endIndex]== ticsToAnalyze['tic'][i])):\n",
        "      retWindow= pd.DataFrame(mainDF.loc[startIndex:endIndex]).reset_index()\n",
        "     #compounded return\n",
        "      retWindow['cum_rf'] = (1 + retWindow['ret']).cumprod()- 1\n",
        "      #compounded risk-free primimum\n",
        "      retWindow['cum_rm_minus_rf'] = (1 + retWindow['rm_minus_rf']).cumprod()\n",
        "      #treasury bill\n",
        "      retWindow['cum_rf'] = (1 + retWindow['rm_minus_rf']).cumprod()-1\n",
        "\n",
        "      #last day of data for rdq\n",
        "      cumRetMinusCumRF.append(retWindow['cum_ret'][endingDay-startingDay]-retWindow['cum_rf'][ b- a])\n",
        "      cumRMMinusRF.append(retWindow['cum_rm_minus_rf'][endingDay - startingDay])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qx4vUBPl04mA"
      },
      "outputs": [],
      "source": [
        "resultsDF= pd.DataFrame()\n",
        "\n",
        "resultsDF['cum_ret_minus_rf']=  cumRetMinusCumRF\n",
        "resultsDF['cum_rm_minus_rf']= cumRMMinusRF\n",
        "\n",
        "return(resultsDF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "13s9Lj9cteDJ"
      },
      "outputs": [],
      "source": [
        "#Run regressions for each decile on each period\n",
        "\n",
        "for j in range(1, 11):\n",
        "  currentTicsToAnalyze = TicOfRDQ[TicOfRDQ['sue_decile'] ==j]\n",
        "  for k in range(len(startingDays)):\n",
        "    dfForTable2Reg= calculateCumRawRetCompounded(startingDays[k], endingDays[k], currentTicsToAnalyze)\n",
        "    tempReg= sm.ols(\"cum_ret_minus_cum_rf~ ccum_rm_minus_rf\", data= dfForTable2Reg).fit()\n",
        "\n",
        "tempRegSummary= tempReg.summary()\n",
        "print(\"Decile = \" + str(j) + \"; starting day of period\" + str(startingDays[k]))\n",
        "print(tempRegSummary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NNPTHX8nXjnA"
      },
      "outputs": [],
      "source": [
        "#Find Rank Correlation ###\n",
        "\n",
        "#Import Regression Results\n",
        "\n",
        "#ADD filepath\n",
        "file= filePath + \"/Table_2A.csv\"\n",
        "\n",
        "table2A= pd.read_csv(file)\n",
        "\n",
        "#Spearman Rank Correlation Test\n",
        "\n",
        "for i in table2A.columns:\n",
        "  print(stats.spearmanr(table2A['sue_decile'], table2A[i]))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "14hFGezyIwbBbsolB6uptDJ2-t6_ytrkS",
      "authorship_tag": "ABX9TyOoz0u2CPk47+Ldu0frUp2S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}